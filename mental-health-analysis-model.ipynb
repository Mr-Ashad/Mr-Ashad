{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mahammadashad/mental-health-analysis-model?scriptVersionId=205598928\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"68ce4cc4","metadata":{"_cell_guid":"eb1bf72a-1b50-46bb-9ead-810dd540f7cf","_uuid":"6e12c425-366e-4ede-9b4e-4d616dac7a46","collapsed":false,"execution":{"iopub.execute_input":"2024-10-15T14:50:52.477972Z","iopub.status.busy":"2024-10-15T14:50:52.47719Z","iopub.status.idle":"2024-10-15T14:50:57.537989Z","shell.execute_reply":"2024-10-15T14:50:57.536964Z","shell.execute_reply.started":"2024-10-15T14:50:52.477921Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.011056,"end_time":"2024-11-06T14:52:08.869686","exception":false,"start_time":"2024-11-06T14:52:08.85863","status":"completed"},"tags":[]},"source":["## Mental Health Classification using Bert and Deepspeed <br>\n","\n","### In this model i have two parts \n","#### 1. Untrained model without using Deepspeed \n","#### 2. train.py file with traning script for Deepspeed training  <br>\n","\n","#### Why i have two parts , its because i have all the preprocessing visualization and other components explained in this notebook so it's easier to understand.\n","#### In the train.py file i have not explained much so i include the first part. \n","\n","#####  Hope this will be of some use , Thank You"]},{"cell_type":"code","execution_count":1,"id":"a7485216","metadata":{"execution":{"iopub.execute_input":"2024-11-06T14:52:08.893803Z","iopub.status.busy":"2024-11-06T14:52:08.893472Z","iopub.status.idle":"2024-11-06T14:52:16.567438Z","shell.execute_reply":"2024-11-06T14:52:16.566233Z"},"papermill":{"duration":7.68892,"end_time":"2024-11-06T14:52:16.570389","exception":false,"start_time":"2024-11-06T14:52:08.881469","status":"completed"},"tags":[]},"outputs":[],"source":["\n","import pandas as pd\n","import re\n","import os\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from transformers import BertTokenizer\n","import torch\n","from torch.utils.data import DataLoader\n","from transformers import BertModel,BertTokenizerFast,BertForSequenceClassification, Adafactor\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"id":"6a073716","metadata":{"_cell_guid":"5ee42e11-6bf6-4db6-8666-e18061bb9582","_uuid":"e1e57aa8-4a49-434b-971a-874d01889511","collapsed":false,"execution":{"iopub.execute_input":"2024-11-06T14:52:16.594503Z","iopub.status.busy":"2024-11-06T14:52:16.593975Z","iopub.status.idle":"2024-11-06T14:52:17.387304Z","shell.execute_reply":"2024-11-06T14:52:17.386201Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.808678,"end_time":"2024-11-06T14:52:17.390189","exception":false,"start_time":"2024-11-06T14:52:16.581511","status":"completed"},"tags":[]},"outputs":[],"source":["df = pd.read_csv(\"/kaggle/input/sentiment-analysis-for-mental-health/Combined Data.csv\")"]},{"cell_type":"code","execution_count":3,"id":"311c0f01","metadata":{"_cell_guid":"909efe06-2a32-43c2-ad3e-5831eb521206","_uuid":"518758d4-1a69-4693-9865-c1e486e24ba8","collapsed":false,"execution":{"iopub.execute_input":"2024-11-06T14:52:17.418085Z","iopub.status.busy":"2024-11-06T14:52:17.417294Z","iopub.status.idle":"2024-11-06T14:52:17.442038Z","shell.execute_reply":"2024-11-06T14:52:17.441089Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.039647,"end_time":"2024-11-06T14:52:17.444642","exception":false,"start_time":"2024-11-06T14:52:17.404995","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>statement</th>\n","      <th>status</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>oh my gosh</td>\n","      <td>Anxiety</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>trouble sleeping, confused mind, restless hear...</td>\n","      <td>Anxiety</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n","      <td>Anxiety</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>I've shifted my focus to something else but I'...</td>\n","      <td>Anxiety</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>I'm restless and restless, it's been a month n...</td>\n","      <td>Anxiety</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>53038</th>\n","      <td>53038</td>\n","      <td>Nobody takes me seriously I’ve (24M) dealt wit...</td>\n","      <td>Anxiety</td>\n","    </tr>\n","    <tr>\n","      <th>53039</th>\n","      <td>53039</td>\n","      <td>selfishness  \"I don't feel very good, it's lik...</td>\n","      <td>Anxiety</td>\n","    </tr>\n","    <tr>\n","      <th>53040</th>\n","      <td>53040</td>\n","      <td>Is there any way to sleep better? I can't slee...</td>\n","      <td>Anxiety</td>\n","    </tr>\n","    <tr>\n","      <th>53041</th>\n","      <td>53041</td>\n","      <td>Public speaking tips? Hi, all. I have to give ...</td>\n","      <td>Anxiety</td>\n","    </tr>\n","    <tr>\n","      <th>53042</th>\n","      <td>53042</td>\n","      <td>I have really bad door anxiety! It's not about...</td>\n","      <td>Anxiety</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>53043 rows × 3 columns</p>\n","</div>"],"text/plain":["       Unnamed: 0                                          statement   status\n","0               0                                         oh my gosh  Anxiety\n","1               1  trouble sleeping, confused mind, restless hear...  Anxiety\n","2               2  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n","3               3  I've shifted my focus to something else but I'...  Anxiety\n","4               4  I'm restless and restless, it's been a month n...  Anxiety\n","...           ...                                                ...      ...\n","53038       53038  Nobody takes me seriously I’ve (24M) dealt wit...  Anxiety\n","53039       53039  selfishness  \"I don't feel very good, it's lik...  Anxiety\n","53040       53040  Is there any way to sleep better? I can't slee...  Anxiety\n","53041       53041  Public speaking tips? Hi, all. I have to give ...  Anxiety\n","53042       53042  I have really bad door anxiety! It's not about...  Anxiety\n","\n","[53043 rows x 3 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":4,"id":"58502393","metadata":{"_cell_guid":"e7bf0855-a72d-4c83-b57e-886836f09dda","_uuid":"12646d36-de53-4c2d-89c7-adf304c7c53c","collapsed":false,"execution":{"iopub.execute_input":"2024-11-06T14:52:17.470304Z","iopub.status.busy":"2024-11-06T14:52:17.469966Z","iopub.status.idle":"2024-11-06T14:52:17.510445Z","shell.execute_reply":"2024-11-06T14:52:17.509244Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.05555,"end_time":"2024-11-06T14:52:17.513155","exception":false,"start_time":"2024-11-06T14:52:17.457605","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 53043 entries, 0 to 53042\n","Data columns (total 3 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   Unnamed: 0  53043 non-null  int64 \n"," 1   statement   52681 non-null  object\n"," 2   status      53043 non-null  object\n","dtypes: int64(1), object(2)\n","memory usage: 1.2+ MB\n"]}],"source":["df.info()"]},{"cell_type":"code","execution_count":5,"id":"87d0fde3","metadata":{"_cell_guid":"8b80baef-ce6e-4644-8557-40736ddc67cb","_uuid":"67ef0611-a1f0-46f7-a1d2-b86c3e1bf61c","collapsed":false,"execution":{"iopub.execute_input":"2024-11-06T14:52:17.5399Z","iopub.status.busy":"2024-11-06T14:52:17.539112Z","iopub.status.idle":"2024-11-06T14:52:17.55172Z","shell.execute_reply":"2024-11-06T14:52:17.550495Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.027131,"end_time":"2024-11-06T14:52:17.553719","exception":false,"start_time":"2024-11-06T14:52:17.526588","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>statement</th>\n","      <th>status</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>oh my gosh</td>\n","      <td>Anxiety</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>trouble sleeping, confused mind, restless heart. All out of tune</td>\n","      <td>Anxiety</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>All wrong, back off dear, forward doubt. Stay in a restless and restless place</td>\n","      <td>Anxiety</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>I've shifted my focus to something else but I'm still worried</td>\n","      <td>Anxiety</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>I'm restless and restless, it's been a month now, boy. What do you mean?</td>\n","      <td>Anxiety</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  \\\n","0           0   \n","1           1   \n","2           2   \n","3           3   \n","4           4   \n","\n","                                                                        statement  \\\n","0                                                                      oh my gosh   \n","1                trouble sleeping, confused mind, restless heart. All out of tune   \n","2  All wrong, back off dear, forward doubt. Stay in a restless and restless place   \n","3                   I've shifted my focus to something else but I'm still worried   \n","4        I'm restless and restless, it's been a month now, boy. What do you mean?   \n","\n","    status  \n","0  Anxiety  \n","1  Anxiety  \n","2  Anxiety  \n","3  Anxiety  \n","4  Anxiety  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Displaying the full length\n","pd.set_option('display.max_colwidth', None)\n","df.head()\n"]},{"cell_type":"markdown","id":"f612e83b","metadata":{"_cell_guid":"a9096e61-4d8e-4f06-bb2d-77d55ea989a3","_uuid":"723dd87d-5fdd-4423-ab7e-3b1d0776e3dc","papermill":{"duration":0.011412,"end_time":"2024-11-06T14:52:17.576051","exception":false,"start_time":"2024-11-06T14:52:17.564639","status":"completed"},"tags":[]},"source":["# Checking for null values"]},{"cell_type":"code","execution_count":6,"id":"65ba96c1","metadata":{"_cell_guid":"0aab04e7-7958-4499-8c2a-7b608c04922a","_uuid":"179966ee-da3b-4344-ad7e-d654423f6d6b","collapsed":false,"execution":{"iopub.execute_input":"2024-11-06T14:52:17.600211Z","iopub.status.busy":"2024-11-06T14:52:17.599514Z","iopub.status.idle":"2024-11-06T14:52:17.624606Z","shell.execute_reply":"2024-11-06T14:52:17.623546Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.040109,"end_time":"2024-11-06T14:52:17.627016","exception":false,"start_time":"2024-11-06T14:52:17.586907","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Unnamed: 0      0\n","statement     362\n","status          0\n","dtype: int64"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().sum()"]},{"cell_type":"code","execution_count":7,"id":"2a74e00f","metadata":{"_cell_guid":"21e41fc0-9d51-49a8-bad3-1ba350eb60f6","_uuid":"8daed9c5-00e9-4543-97e9-82f1e601bb16","collapsed":false,"execution":{"iopub.execute_input":"2024-11-06T14:52:17.655907Z","iopub.status.busy":"2024-11-06T14:52:17.655582Z","iopub.status.idle":"2024-11-06T14:52:17.675973Z","shell.execute_reply":"2024-11-06T14:52:17.675193Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.037674,"end_time":"2024-11-06T14:52:17.677888","exception":false,"start_time":"2024-11-06T14:52:17.640214","status":"completed"},"tags":[]},"outputs":[],"source":["#Removing Null Values\n","df.dropna(inplace=True)"]},{"cell_type":"code","execution_count":8,"id":"bfcabb8d","metadata":{"_cell_guid":"3fc1626c-2d8b-49fe-8643-0298135f2d45","_uuid":"379a58b2-3aa5-495a-9c9b-3d5407db516e","collapsed":false,"execution":{"iopub.execute_input":"2024-11-06T14:52:17.702083Z","iopub.status.busy":"2024-11-06T14:52:17.701791Z","iopub.status.idle":"2024-11-06T14:52:17.721112Z","shell.execute_reply":"2024-11-06T14:52:17.720158Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.033767,"end_time":"2024-11-06T14:52:17.723295","exception":false,"start_time":"2024-11-06T14:52:17.689528","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Unnamed: 0    0\n","statement     0\n","status        0\n","dtype: int64"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().sum()"]},{"cell_type":"code","execution_count":9,"id":"822be249","metadata":{"_cell_guid":"b9c4b366-46c9-4684-9add-30974f0a9a23","_uuid":"f3365897-89b1-4763-aead-d820c38e4cec","collapsed":false,"execution":{"iopub.execute_input":"2024-11-06T14:52:17.749898Z","iopub.status.busy":"2024-11-06T14:52:17.74961Z","iopub.status.idle":"2024-11-06T14:52:17.757345Z","shell.execute_reply":"2024-11-06T14:52:17.756322Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.023763,"end_time":"2024-11-06T14:52:17.75962","exception":false,"start_time":"2024-11-06T14:52:17.735857","status":"completed"},"tags":[]},"outputs":[],"source":["# Converting 'statement' to column to string for using it in BERTokenizer\n","\n","df[\"str_statement\"]= df[\"statement\"].astype(str)"]},{"cell_type":"code","execution_count":10,"id":"5adc19de","metadata":{"_cell_guid":"620156b4-8cbe-4891-b501-1895c3439b64","_uuid":"062642f7-8194-4d5b-befa-153f69b86dbd","collapsed":false,"execution":{"iopub.execute_input":"2024-11-06T14:52:17.786333Z","iopub.status.busy":"2024-11-06T14:52:17.785949Z","iopub.status.idle":"2024-11-06T14:52:17.79399Z","shell.execute_reply":"2024-11-06T14:52:17.79287Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.023901,"end_time":"2024-11-06T14:52:17.796275","exception":false,"start_time":"2024-11-06T14:52:17.772374","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["0                                                                        oh my gosh\n","1                  trouble sleeping, confused mind, restless heart. All out of tune\n","2    All wrong, back off dear, forward doubt. Stay in a restless and restless place\n","3                     I've shifted my focus to something else but I'm still worried\n","4          I'm restless and restless, it's been a month now, boy. What do you mean?\n","Name: str_statement, dtype: object"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df[\"str_statement\"].head()"]},{"cell_type":"markdown","id":"53816776","metadata":{"_cell_guid":"a8afa27a-f5ad-4eb7-8269-8e4782e732e8","_uuid":"d53fd78d-8876-47dd-a64d-59381fec52e8","papermill":{"duration":0.012269,"end_time":"2024-11-06T14:52:17.8213","exception":false,"start_time":"2024-11-06T14:52:17.809031","status":"completed"},"tags":[]},"source":["# Covert to lowercase"]},{"cell_type":"code","execution_count":11,"id":"7a36d3b5","metadata":{"_cell_guid":"0be010d2-f33d-4c07-a631-ef6aee1e0b2e","_uuid":"dc6f518c-e7f1-466f-a4d6-6ca5d8b518a0","collapsed":false,"execution":{"iopub.execute_input":"2024-11-06T14:52:17.84858Z","iopub.status.busy":"2024-11-06T14:52:17.84798Z","iopub.status.idle":"2024-11-06T14:52:17.964471Z","shell.execute_reply":"2024-11-06T14:52:17.963606Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.132703,"end_time":"2024-11-06T14:52:17.966973","exception":false,"start_time":"2024-11-06T14:52:17.83427","status":"completed"},"tags":[]},"outputs":[],"source":["df['str_statement'] = df['statement'].str.lower()"]},{"cell_type":"code","execution_count":12,"id":"e0d19cd8","metadata":{"_cell_guid":"b72dc993-cf4c-46bf-8815-b21a9d9465e9","_uuid":"c7489b83-e466-4c74-babf-de828412b204","collapsed":false,"execution":{"iopub.execute_input":"2024-11-06T14:52:17.997292Z","iopub.status.busy":"2024-11-06T14:52:17.996733Z","iopub.status.idle":"2024-11-06T14:52:18.004338Z","shell.execute_reply":"2024-11-06T14:52:18.003304Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.025953,"end_time":"2024-11-06T14:52:18.006796","exception":false,"start_time":"2024-11-06T14:52:17.980843","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["0                                                                        oh my gosh\n","1                  trouble sleeping, confused mind, restless heart. all out of tune\n","2    all wrong, back off dear, forward doubt. stay in a restless and restless place\n","3                     i've shifted my focus to something else but i'm still worried\n","4          i'm restless and restless, it's been a month now, boy. what do you mean?\n","Name: str_statement, dtype: object"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df[\"str_statement\"].head()"]},{"cell_type":"markdown","id":"6b803af7","metadata":{"_cell_guid":"5e91ffb6-655e-4b0f-87c2-3d9fdce6aadd","_uuid":"49f45c8a-6ca5-441f-b7dd-644127d4c03b","papermill":{"duration":0.012139,"end_time":"2024-11-06T14:52:18.032223","exception":false,"start_time":"2024-11-06T14:52:18.020084","status":"completed"},"tags":[]},"source":["# Remove links and unwanted things like username,links etc"]},{"cell_type":"code","execution_count":13,"id":"96f8757b","metadata":{"_cell_guid":"37e0b7fe-bcae-4691-b572-5102f99ceb4c","_uuid":"fc4ebe04-6acc-4525-8e3e-8433ce1f8fb7","collapsed":false,"execution":{"iopub.execute_input":"2024-11-06T14:52:18.057719Z","iopub.status.busy":"2024-11-06T14:52:18.057385Z","iopub.status.idle":"2024-11-06T14:52:19.693796Z","shell.execute_reply":"2024-11-06T14:52:19.692716Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":1.652493,"end_time":"2024-11-06T14:52:19.69631","exception":false,"start_time":"2024-11-06T14:52:18.043817","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>statement</th>\n","      <th>status</th>\n","      <th>str_statement</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>oh my gosh</td>\n","      <td>Anxiety</td>\n","      <td>oh my gosh</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>trouble sleeping, confused mind, restless heart. All out of tune</td>\n","      <td>Anxiety</td>\n","      <td>trouble sleeping confused mind restless heart all out of tune</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>All wrong, back off dear, forward doubt. Stay in a restless and restless place</td>\n","      <td>Anxiety</td>\n","      <td>all wrong back off dear forward doubt stay in a restless and restless place</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>I've shifted my focus to something else but I'm still worried</td>\n","      <td>Anxiety</td>\n","      <td>ive shifted my focus to something else but im still worried</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>I'm restless and restless, it's been a month now, boy. What do you mean?</td>\n","      <td>Anxiety</td>\n","      <td>im restless and restless its been a month now boy what do you mean</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  \\\n","0           0   \n","1           1   \n","2           2   \n","3           3   \n","4           4   \n","\n","                                                                        statement  \\\n","0                                                                      oh my gosh   \n","1                trouble sleeping, confused mind, restless heart. All out of tune   \n","2  All wrong, back off dear, forward doubt. Stay in a restless and restless place   \n","3                   I've shifted my focus to something else but I'm still worried   \n","4        I'm restless and restless, it's been a month now, boy. What do you mean?   \n","\n","    status  \\\n","0  Anxiety   \n","1  Anxiety   \n","2  Anxiety   \n","3  Anxiety   \n","4  Anxiety   \n","\n","                                                                 str_statement  \n","0                                                                   oh my gosh  \n","1                trouble sleeping confused mind restless heart all out of tune  \n","2  all wrong back off dear forward doubt stay in a restless and restless place  \n","3                  ive shifted my focus to something else but im still worried  \n","4           im restless and restless its been a month now boy what do you mean  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["def remove_patterns(text):\n","    # URL Removal\n","    text = re.sub(r'http[s]?://\\S+','',text)\n","    # Remove markdown style links\n","    text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)\n","    # Remove handles (that start with '@')\n","    text = re.sub(r'@\\w+', '', text)\n","    # Remove punctuation and other special characters\n","    text = re.sub(r'[^\\w\\s]', '', text)\n","    return text.strip()\n","    \n","df['str_statement'] = df['str_statement'].apply(remove_patterns)\n","df.head()"]},{"cell_type":"markdown","id":"54311bb3","metadata":{"_cell_guid":"ee0c145b-6768-41a6-be92-341bedfea77c","_uuid":"72eeb653-5155-432e-9499-a2bb7872025b","papermill":{"duration":0.013087,"end_time":"2024-11-06T14:52:19.724446","exception":false,"start_time":"2024-11-06T14:52:19.711359","status":"completed"},"tags":[]},"source":["# Convert the labels (strings) to integers using Label Encoder"]},{"cell_type":"code","execution_count":14,"id":"6a9ddcab","metadata":{"_cell_guid":"18d50e00-5fe8-4325-bcb6-4b4eab44f579","_uuid":"578d5327-cc12-479e-858b-09f3b4348341","collapsed":false,"execution":{"iopub.execute_input":"2024-11-06T14:52:19.75289Z","iopub.status.busy":"2024-11-06T14:52:19.752017Z","iopub.status.idle":"2024-11-06T14:52:19.771502Z","shell.execute_reply":"2024-11-06T14:52:19.770478Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.03582,"end_time":"2024-11-06T14:52:19.773632","exception":false,"start_time":"2024-11-06T14:52:19.737812","status":"completed"},"tags":[]},"outputs":[],"source":["label_encoder = LabelEncoder()\n","df['encoded_status'] = label_encoder.fit_transform(df['status'])"]},{"cell_type":"markdown","id":"669b4153","metadata":{"_cell_guid":"2fbb9c36-dd77-4dc4-b2f4-2fb05ef26de5","_uuid":"79e07f4a-c063-4a88-86bc-bb823e4a9480","execution":{"iopub.execute_input":"2024-09-26T13:04:47.194453Z","iopub.status.busy":"2024-09-26T13:04:47.193597Z","iopub.status.idle":"2024-09-26T13:04:47.198183Z","shell.execute_reply":"2024-09-26T13:04:47.197378Z","shell.execute_reply.started":"2024-09-26T13:04:47.194411Z"},"papermill":{"duration":0.012855,"end_time":"2024-11-06T14:52:19.799568","exception":false,"start_time":"2024-11-06T14:52:19.786713","status":"completed"},"tags":[]},"source":["# Splitting the data and Tokenzation using BertTokenizerFast"]},{"cell_type":"code","execution_count":15,"id":"dc2a9f2b","metadata":{"execution":{"iopub.execute_input":"2024-11-06T14:52:19.826814Z","iopub.status.busy":"2024-11-06T14:52:19.826501Z","iopub.status.idle":"2024-11-06T14:52:21.267391Z","shell.execute_reply":"2024-11-06T14:52:21.266277Z"},"papermill":{"duration":1.456849,"end_time":"2024-11-06T14:52:21.269754","exception":false,"start_time":"2024-11-06T14:52:19.812905","status":"completed"},"tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"604d4a16b5774e68a9fe27c921c1322e","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"159f1db4674a42b08601d2544f702421","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"446d62f8b11647408abbe324392b0aec","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec5290d9e6f14452bdea90b2cce603b5","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}],"source":["# Initialize the tokenizer for the pre-trained BERT model\n","tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"]},{"cell_type":"markdown","id":"6fb9811a","metadata":{"execution":{"iopub.execute_input":"2024-10-15T14:48:26.612613Z","iopub.status.busy":"2024-10-15T14:48:26.61159Z","iopub.status.idle":"2024-10-15T14:48:26.617671Z","shell.execute_reply":"2024-10-15T14:48:26.616589Z","shell.execute_reply.started":"2024-10-15T14:48:26.612543Z"},"papermill":{"duration":0.01302,"end_time":"2024-11-06T14:52:21.296632","exception":false,"start_time":"2024-11-06T14:52:21.283612","status":"completed"},"tags":[]},"source":["## Split the dataset into training and validation sets"]},{"cell_type":"code","execution_count":16,"id":"08e23e93","metadata":{"_cell_guid":"17fc04ce-f6ab-4753-889b-b529943d503c","_uuid":"01c48a3d-7065-417c-bf12-32f335a32035","collapsed":false,"execution":{"iopub.execute_input":"2024-11-06T14:52:21.326531Z","iopub.status.busy":"2024-11-06T14:52:21.32612Z","iopub.status.idle":"2024-11-06T14:52:21.339684Z","shell.execute_reply":"2024-11-06T14:52:21.338899Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.031459,"end_time":"2024-11-06T14:52:21.341973","exception":false,"start_time":"2024-11-06T14:52:21.310514","status":"completed"},"tags":[]},"outputs":[],"source":["train_texts, val_texts, train_labels, val_labels = train_test_split(\n","    df['str_statement'],  \n","    df['encoded_status'],\n","    test_size=0.25, # Here 25 percent of the dat will be used for validation\n","    random_state=42\n",")"]},{"cell_type":"code","execution_count":17,"id":"0f994bbb","metadata":{"_cell_guid":"1c63c8d9-8045-4eb2-9b6d-5a2a79eb0bc9","_uuid":"ff444186-5f35-4a1d-a978-b564d427e374","collapsed":false,"execution":{"iopub.execute_input":"2024-11-06T14:52:21.372304Z","iopub.status.busy":"2024-11-06T14:52:21.371919Z","iopub.status.idle":"2024-11-06T14:53:03.940527Z","shell.execute_reply":"2024-11-06T14:53:03.939307Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":42.586791,"end_time":"2024-11-06T14:53:03.943293","exception":false,"start_time":"2024-11-06T14:52:21.356502","status":"completed"},"tags":[]},"outputs":[],"source":["# Tokenization using BERTTokenizerFAst\n","\n","max_length= 512\n","train_encodings= tokenizer(train_texts.tolist(),padding='max_length',truncation=True,return_tensors='pt') # Here it will return the tokens as tensors\n","val_encodings =tokenizer(val_texts.tolist(),padding='max_length',truncation=True,return_tensors='pt')"]},{"cell_type":"markdown","id":"c4fcc2ee","metadata":{"_cell_guid":"3b37c7dc-6cc5-4388-be58-35b8bede3d95","_uuid":"61175f93-d1aa-43a4-9af6-2e6722d3c04a","papermill":{"duration":0.013338,"end_time":"2024-11-06T14:53:03.970965","exception":false,"start_time":"2024-11-06T14:53:03.957627","status":"completed"},"tags":[]},"source":["# Convert the tokenized encodings to a PyTorch dataset"]},{"cell_type":"code","execution_count":18,"id":"ef51182c","metadata":{"_cell_guid":"e311e84d-fae9-4a78-a8b6-fb8ffc0d566b","_uuid":"54d14db9-23a7-4977-8dc0-812b85a5ded7","collapsed":false,"execution":{"iopub.execute_input":"2024-11-06T14:53:03.999187Z","iopub.status.busy":"2024-11-06T14:53:03.998806Z","iopub.status.idle":"2024-11-06T14:53:04.025263Z","shell.execute_reply":"2024-11-06T14:53:04.024294Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.043227,"end_time":"2024-11-06T14:53:04.027513","exception":false,"start_time":"2024-11-06T14:53:03.984286","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","\n","class MentalHealthDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = torch.tensor(labels)\n","\n","    def __getitem__(self, idx):\n","        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n","        item['labels'] = self.labels[idx].clone().detach()\n","\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","# Create the datasets\n","train_dataset = MentalHealthDataset(train_encodings, train_labels.tolist()) # You need to convert it to list \n","val_dataset = MentalHealthDataset(val_encodings, val_labels.tolist()) # You need to convert it to list "]},{"cell_type":"code","execution_count":19,"id":"d8335d5c","metadata":{"_cell_guid":"71ab5a01-0c33-4c40-8798-2b4e024f0209","_uuid":"ff5eff96-ad0a-4a6e-835d-8003bf3b8864","collapsed":false,"execution":{"iopub.execute_input":"2024-11-06T14:53:04.058288Z","iopub.status.busy":"2024-11-06T14:53:04.057902Z","iopub.status.idle":"2024-11-06T14:53:04.064743Z","shell.execute_reply":"2024-11-06T14:53:04.063861Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.024807,"end_time":"2024-11-06T14:53:04.066905","exception":false,"start_time":"2024-11-06T14:53:04.042098","status":"completed"},"tags":[]},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","# Create DataLoader for both training and validation datasets\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,num_workers=2) # You can change batch size as per your need\n","val_loader = DataLoader(val_dataset,  batch_size=32)"]},{"cell_type":"markdown","id":"1b570537","metadata":{"papermill":{"duration":0.014408,"end_time":"2024-11-06T14:53:04.095918","exception":false,"start_time":"2024-11-06T14:53:04.08151","status":"completed"},"tags":[]},"source":["Initializing "]},{"cell_type":"code","execution_count":20,"id":"4984f133","metadata":{"_cell_guid":"d70fba4c-2955-4fdc-9775-426729df8fd1","_uuid":"06d65886-7c76-490a-832c-26b0e5e48392","collapsed":false,"execution":{"iopub.execute_input":"2024-11-06T14:53:04.127019Z","iopub.status.busy":"2024-11-06T14:53:04.126659Z","iopub.status.idle":"2024-11-06T14:53:06.524519Z","shell.execute_reply":"2024-11-06T14:53:06.523798Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":2.416042,"end_time":"2024-11-06T14:53:06.526568","exception":false,"start_time":"2024-11-06T14:53:04.110526","status":"completed"},"tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e1c08741d8a43e4bb8234d7692abb9a","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=7) "]},{"cell_type":"code","execution_count":21,"id":"7340e633","metadata":{"_cell_guid":"08672bc4-bfe1-474b-b821-3f75f4a03110","_uuid":"c1838ef3-9f6f-4fb1-9922-d84f7fe0b3e5","collapsed":false,"execution":{"iopub.execute_input":"2024-11-06T14:53:06.55716Z","iopub.status.busy":"2024-11-06T14:53:06.556817Z","iopub.status.idle":"2024-11-06T14:53:06.992732Z","shell.execute_reply":"2024-11-06T14:53:06.991701Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.45377,"end_time":"2024-11-06T14:53:06.994969","exception":false,"start_time":"2024-11-06T14:53:06.541199","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",")"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# Move model to GPU (if available)\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model.to(device)"]},{"cell_type":"markdown","id":"cbb129fa","metadata":{"papermill":{"duration":0.014307,"end_time":"2024-11-06T14:53:07.024418","exception":false,"start_time":"2024-11-06T14:53:07.010111","status":"completed"},"tags":[]},"source":["## You are free to use whatever type of trainers you want after this part for your purpose"]},{"cell_type":"markdown","id":"68800b8f","metadata":{"papermill":{"duration":0.014407,"end_time":"2024-11-06T14:53:07.053662","exception":false,"start_time":"2024-11-06T14:53:07.039255","status":"completed"},"tags":[]},"source":["<bR> --------------------------------------------------------------------------------------"]},{"cell_type":"markdown","id":"7e3c18ea","metadata":{"papermill":{"duration":0.014303,"end_time":"2024-11-06T14:53:07.082747","exception":false,"start_time":"2024-11-06T14:53:07.068444","status":"completed"},"tags":[]},"source":["# Deepspeed Part"]},{"cell_type":"code","execution_count":22,"id":"007820e8","metadata":{"_cell_guid":"e2f639e8-7db5-4bcf-b9d1-018d85b195c1","_uuid":"d3e9ecef-faca-40b9-a8cb-c62355926e37","execution":{"iopub.execute_input":"2024-11-06T14:53:07.112785Z","iopub.status.busy":"2024-11-06T14:53:07.112004Z","iopub.status.idle":"2024-11-06T14:53:40.226437Z","shell.execute_reply":"2024-11-06T14:53:40.225556Z"},"papermill":{"duration":33.13235,"end_time":"2024-11-06T14:53:40.228884","exception":false,"start_time":"2024-11-06T14:53:07.096534","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Collecting deepspeed\r\n","  Downloading deepspeed-0.15.3.tar.gz (1.4 MB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n","\u001b[?25hCollecting hjson (from deepspeed)\r\n","  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\r\n","Requirement already satisfied: msgpack in /opt/conda/lib/python3.10/site-packages (from deepspeed) (1.0.8)\r\n","Requirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from deepspeed) (1.11.1.1)\r\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from deepspeed) (1.26.4)\r\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from deepspeed) (21.3)\r\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from deepspeed) (5.9.3)\r\n","Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from deepspeed) (9.0.0)\r\n","Requirement already satisfied: pydantic>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from deepspeed) (2.9.2)\r\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from deepspeed) (2.4.0)\r\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from deepspeed) (4.66.4)\r\n","Requirement already satisfied: nvidia-ml-py in /opt/conda/lib/python3.10/site-packages (from deepspeed) (11.495.46)\r\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->deepspeed) (3.1.2)\r\n","Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\r\n","Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed) (2.23.4)\r\n","Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed) (4.12.2)\r\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed) (3.15.1)\r\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed) (1.13.3)\r\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed) (3.3)\r\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed) (3.1.4)\r\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed) (2024.6.1)\r\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->deepspeed) (2.1.5)\r\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->deepspeed) (1.3.0)\r\n","Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hBuilding wheels for collected packages: deepspeed\r\n","  Building wheel for deepspeed (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n","\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.15.3-py3-none-any.whl size=1526207 sha256=fc5896da71aaf35de0248cc54238d5d34599c036f19e42f506e5990890fc5c7d\r\n","  Stored in directory: /root/.cache/pip/wheels/b3/c2/9f/37a2c813b8d64d7908793319cfdfa4f852754e177f20f0b858\r\n","Successfully built deepspeed\r\n","Installing collected packages: hjson, deepspeed\r\n","Successfully installed deepspeed-0.15.3 hjson-3.1.0\r\n","[2024-11-06 14:53:37,895] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/compiler_compat/ld: cannot find -laio: No such file or directory\n","collect2: error: ld returned 1 exit status\n","/opt/conda/compiler_compat/ld: cannot find -laio: No such file or directory\n","collect2: error: ld returned 1 exit status\n"]}],"source":["!pip install deepspeed\n","import deepspeed"]},{"cell_type":"markdown","id":"1316b251","metadata":{"papermill":{"duration":0.017216,"end_time":"2024-11-06T14:53:40.263792","exception":false,"start_time":"2024-11-06T14:53:40.246576","status":"completed"},"tags":[]},"source":["## You need mpi4y to run deepspeed"]},{"cell_type":"code","execution_count":23,"id":"4430e1f5","metadata":{"execution":{"iopub.execute_input":"2024-11-06T14:53:40.299617Z","iopub.status.busy":"2024-11-06T14:53:40.299012Z","iopub.status.idle":"2024-11-06T14:55:15.511944Z","shell.execute_reply":"2024-11-06T14:55:15.510589Z"},"papermill":{"duration":95.233216,"end_time":"2024-11-06T14:55:15.514299","exception":false,"start_time":"2024-11-06T14:53:40.281083","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Retrieving notices: ...working... done\r\n","Channels:\r\n"," - rapidsai\r\n"," - nvidia\r\n"," - nodefaults\r\n"," - conda-forge\r\n"," - defaults\r\n"," - pytorch\r\n","Platform: linux-64\r\n","Collecting package metadata (repodata.json): \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\r\n","Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\r\n","\r\n","## Package Plan ##\r\n","\r\n","  environment location: /opt/conda\r\n","\r\n","  added / updated specs:\r\n","    - mpi4py\r\n","\r\n","\r\n","The following packages will be downloaded:\r\n","\r\n","    package                    |            build\r\n","    ---------------------------|-----------------\r\n","    conda-24.9.2               |  py310hff52083_0         895 KB  conda-forge\r\n","    mpi-1.0.1                  |            mpich           6 KB  conda-forge\r\n","    mpi4py-4.0.1               |  py310hc9139ab_0         802 KB  conda-forge\r\n","    mpich-4.2.3                |     h670b19f_100        13.1 MB  conda-forge\r\n","    ------------------------------------------------------------\r\n","                                           Total:        14.8 MB\r\n","\r\n","The following NEW packages will be INSTALLED:\r\n","\r\n","  mpi                conda-forge/noarch::mpi-1.0.1-mpich \r\n","  mpi4py             conda-forge/linux-64::mpi4py-4.0.1-py310hc9139ab_0 \r\n","  mpich              conda-forge/linux-64::mpich-4.2.3-h670b19f_100 \r\n","\r\n","The following packages will be UPDATED:\r\n","\r\n","  conda                              24.9.0-py310hff52083_0 --> 24.9.2-py310hff52083_0 \r\n","\r\n","\r\n","\r\n","Downloading and Extracting Packages:\r\n","mpich-4.2.3          | 13.1 MB   |                                       |   0% \r\n","conda-24.9.2         | 895 KB    |                                       |   0% \u001b[A\r\n","\r\n","mpi4py-4.0.1         | 802 KB    |                                       |   0% \u001b[A\u001b[A\r\n","\r\n","\r\n","mpich-4.2.3          | 13.1 MB   |                                       |   0% \r\n","\r\n","\r\n","mpi-1.0.1            | 6 KB      | ##################################### | 100% \u001b[A\u001b[A\u001b[A\r\n","\r\n","\r\n","mpi-1.0.1            | 6 KB      | ##################################### | 100% \u001b[A\u001b[A\u001b[A\r\n","conda-24.9.2         | 895 KB    | 6                                     |   2% \u001b[A\r\n","\r\n","mpich-4.2.3          | 13.1 MB   | ###############################7      |  86% \r\n","\r\n","mpi4py-4.0.1         | 802 KB    | ##################################### | 100% \u001b[A\u001b[A\r\n","\r\n","mpi4py-4.0.1         | 802 KB    | ##################################### | 100% \u001b[A\u001b[A\r\n","conda-24.9.2         | 895 KB    | ##################################### | 100% \u001b[A\r\n","\r\n","                                                                                \u001b[A\r\n","\r\n","                                                                                \u001b[A\u001b[A\r\n","\r\n","\r\n","\r\n","Preparing transaction: \\ \b\b| \b\bdone\r\n","Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\r\n","Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\r\n"]}],"source":["!conda install -y mpi4py"]},{"cell_type":"markdown","id":"f9d6fcf8","metadata":{"papermill":{"duration":0.031659,"end_time":"2024-11-06T14:55:15.578235","exception":false,"start_time":"2024-11-06T14:55:15.546576","status":"completed"},"tags":[]},"source":["# To run train the model using Deepseed while utilizing multiple gpu \n","##### (kaggle does not have native multi-gpu processing(CLI) support.<br>\n","\n","\n","#### **1. Create a .py file with all the preprocessing and working of the model inside a main function using %%write(as below)**\n","(You can convert a notebook file to .py by going to the file section and selcting script in editor type)\n","\n","#### 2. add  if ＿name＿ == '＿main＿': main() at the end of the file \n","\n","#### 3. Run using accelerate launch\n"]},{"cell_type":"code","execution_count":24,"id":"664fcc66","metadata":{"execution":{"iopub.execute_input":"2024-11-06T14:55:15.645837Z","iopub.status.busy":"2024-11-06T14:55:15.64541Z","iopub.status.idle":"2024-11-06T14:55:15.660405Z","shell.execute_reply":"2024-11-06T14:55:15.658491Z"},"papermill":{"duration":0.052134,"end_time":"2024-11-06T14:55:15.662715","exception":false,"start_time":"2024-11-06T14:55:15.610581","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing train.py\n"]}],"source":["%%writefile train.py\n","\n","def main():\n","    \n","    # Import necessary packages\n","    import pandas as pd\n","    import re\n","    from sklearn.preprocessing import LabelEncoder\n","    from sklearn.model_selection import train_test_split\n","    from transformers import BertTokenizerFast, BertForSequenceClassification\n","    import torch\n","    from torch import nn\n","    from torch.utils.data import DataLoader\n","    from transformers import Adafactor\n","    from tqdm import tqdm\n","    import deepspeed\n","    import json\n","    from accelerate import Accelerator\n","    from torch.optim import AdamW\n","    from transformers import get_linear_schedule_with_warmup\n","    from sklearn.metrics import f1_score, classification_report\n","\n","    # Load dataset\n","    df = pd.read_csv(\"/kaggle/input/sentiment-analysis-for-mental-health/Combined Data.csv\")\n","\n","    # Convert 'statement' column to string\n","    df[\"str_statement\"] = df[\"statement\"].astype(str)\n","    # Ensure all values in 'str_statement' are strings\n","    df[\"str_statement\"] = df[\"str_statement\"].astype(str)\n","\n","    # Convert to lowercase\n","    df['str_statement'] = df['str_statement'].str.lower()\n","    \n","    def remove_patterns(text):\n","        if isinstance(text, str):\n","            # URL Removal\n","            text = re.sub(r'http[s]?://\\S+','',text)\n","            # Remove markdown style links\n","            text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)\n","            # Remove handles (that start with '@')\n","            text = re.sub(r'@\\w+', '', text)\n","            # Remove punctuation and other special characters\n","            text = re.sub(r'[^\\w\\s]', '', text)\n","            return text.strip()\n","    \n","    df['str_statement'] = df['str_statement'].apply(remove_patterns)\n","\n","    df.dropna(inplace=True)\n","    \n","    # Label encoding\n","    label_encoder = LabelEncoder()\n","    df['encoded_status'] = label_encoder.fit_transform(df['status'])\n","    \n","    # Initialize the tokenizer for BERT\n","    tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n","\n","    # Split data into training and validation sets\n","    train_texts, val_texts, train_labels, val_labels = train_test_split(\n","        df['str_statement'], df['encoded_status'], test_size=0.25, random_state=42\n","    )\n","\n","    # Tokenization\n","    max_length = 512\n","    train_encodings = tokenizer(train_texts.tolist(), padding='max_length', truncation=True, return_tensors='pt')\n","    val_encodings = tokenizer(val_texts.tolist(), padding='max_length', truncation=True, return_tensors='pt')\n","\n","    # PyTorch Dataset Class\n","    class MentalHealthDataset(torch.utils.data.Dataset):\n","        def __init__(self, encodings, labels):\n","            self.encodings = encodings\n","            self.labels = torch.tensor(labels)\n","\n","        def __getitem__(self, idx):\n","            item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n","            item['labels'] = self.labels[idx].clone().detach()\n","            return item\n","\n","        def __len__(self):\n","            return len(self.labels)\n","\n","    # Create datasets\n","    train_dataset = MentalHealthDataset(train_encodings, train_labels.tolist())\n","    val_dataset = MentalHealthDataset(val_encodings, val_labels.tolist())\n","\n","    # Create DataLoader for both training and validation datasets\n","    train_loader = DataLoader(train_dataset, batch_size=54, shuffle=True,pin_memory=True)\n","    val_loader = DataLoader(val_dataset, batch_size=54)\n","\n","    # Define the BERT model\n","    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=7)\n","\n","    # Move model to GPU (if available)\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","    model.to(device)\n","\n","    ds_config =\"\"\"\n","    {\n","    \"train_batch_size\": 54,\n","    \"gradient_accumulation_steps\": 1,\n","    \"fp16\": {\n","        \"enabled\": true,\n","        \"min_loss_scale\":1\n","    },\n","    \"zero_optimization\": {\n","        \"stage\": 2,\n","        \"allgather_partitions\": true,\n","        \"reduce_scatter\": true,\n","        \"overlap_comm\": true,\n","        \"cpu_offload\": true\n","    },\n","    \"autotuning\": {\n","        \"enabled\": true,\n","        \"arg_mappings\": {\n","            \"train_micro_batch_size_per_gpu\": \"--per_device_train_batch_size\",\n","            \"gradient_accumulation_steps\": \"--gradient_accumulation_steps\"\n","        }\n","        },\n","    \"gradient_clipping\": 1.0,\n","    \"results_dir\": \"./autotuning_results\",\n","    \"exps_dir\": \"./autotuning_exps\",\n","    \"zero_allow_untested_optimizer\": true,\n","    \"steps_per_print\": 2000,\n","    \"wall_clock_breakdown\": false,\n","    \"scheduler\": {\n","    \"type\": \"WarmupLR\",\n","    \"params\": {\n","      \"warmup_min_lr\": 0,\n","      \"warmup_max_lr\": 0.001,\n","      \"warmup_num_steps\": 1000\n","      }\n","      }\n","    \"optimizer\": {\n","           \"type\": \"AdamW\",\n","           \"params\": {\n","               \"lr\": 1e-4,\n","               \"betas\": [0.9, 0.999],\n","               \"eps\": 1e-8,\n","               \"weight_decay\": 0.01\n","        }   \n","      }\n","    }\n","\n","    \"\"\"\n","    # DeepSpeed Initialization\n","    with open(\"ds_config.json\", \"w\") as f:\n","        f.write(ds_config)\n","   \n","    #optimizer = AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\n","    model_engine,optimizer, _, _ = deepspeed.initialize(\n","    model=model,\n","    config=\"ds_config.json\" )\n","    \n","    model = model.to(device)\n","    \n","    accelerator = Accelerator()\n","    \n","    # Training loop\n","    from tqdm import tqdm\n","    from collections import OrderedDict\n","    \n","    criterion = nn.CrossEntropyLoss()\n","    epochs = 3\n","    num_batches = len(train_loader)\n","    total_steps = (num_batches) * (epochs)\n","\n","\n","    def train_one_epoch(model, train_loader,criterion,optimizer,accelarator, device):\n","        model.train()  # Set model to training mode\n","        total_loss = 0\n","\n","        # Use tqdm for progress bar\n","        with tqdm(train_loader, leave=True, disable=not accelerator.is_local_main_process) as pbar:\n","            for idx, batch in enumerate(pbar):\n","                batch = {k: v.to(device) for k, v in batch.items()}  # Move batch to device\n","\n","                outputs = model(**batch)\n","                loss = outputs.loss  # Assuming outputs has a loss attribute\n","            \n","                # Backward pass with accelerator\n","                model_engine.backward(loss)  # Automatic handling of backward pass\n","            \n","                # Update the loss and progress bar\n","                total_loss += loss.item()\n","\n","                # Step the optimizer\n","                optimizer.step()\n","                optimizer.zero_grad()  # Clear gradients\n","            \n","                # Update the progress bar\n","                pbar.update(1)  \n","            \n","\n","        # Wait for all processes to finish\n","        accelerator.wait_for_everyone()\n","        # Log average loss\n","        accelerator.print(f'train_loss: {total_loss / len(train_loader):.6f}')\n","\n","    # Training loop\n","    for epoch in range(epochs):\n","        train_one_epoch(model, train_loader,criterion, optimizer, accelerator, device)\n","        print(f\"Epoch {epoch + 1} completed.\")\n","\n","\n","    torch.cuda.empty_cache() # Clear CUDA memory\n","    \n","    # Move model to GPU (if available)\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","    model.to(device)\n","\n","    model.eval()\n","    if torch.cuda.device_count() > 1:\n","        model = torch.nn.DataParallel(model)\n","\n","    \n","    val_loader = DataLoader(val_dataset, batch_size=128)\n","\n","    # Store predictions and true labels\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(val_loader, desc=\"Making Predictions\", unit=\"batch\"):\n","            # Move the batch to the GPU (if available)\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            # Forward pass\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            logits = outputs.logits\n","\n","            # Get the predicted labels\n","            preds = torch.argmax(logits, dim=1).cpu().numpy()\n","            labels = labels.cpu().numpy()\n","\n","            # Store predictions and true labels\n","            all_preds.extend(preds)\n","            all_labels.extend(labels)\n","\n","    # Calculate the F1-score\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","    print(f'Validation F1-score: {f1:.4f}')\n","\n","\n","    # Save the trained model\n","    model.save_pretrained(\"./trained_model\")\n","    \n","if __name__ == '__main__':\n","    main()\n"]},{"cell_type":"code","execution_count":25,"id":"0cba3014","metadata":{"execution":{"iopub.execute_input":"2024-11-06T14:55:15.730007Z","iopub.status.busy":"2024-11-06T14:55:15.72967Z","iopub.status.idle":"2024-11-06T14:55:15.73407Z","shell.execute_reply":"2024-11-06T14:55:15.733017Z"},"papermill":{"duration":0.039957,"end_time":"2024-11-06T14:55:15.736263","exception":false,"start_time":"2024-11-06T14:55:15.696306","status":"completed"},"tags":[]},"outputs":[],"source":["import accelerate"]},{"cell_type":"markdown","id":"2842adfc","metadata":{"papermill":{"duration":0.032291,"end_time":"2024-11-06T14:55:15.801012","exception":false,"start_time":"2024-11-06T14:55:15.768721","status":"completed"},"tags":[]},"source":["## Start training using accelerate launch"]},{"cell_type":"code","execution_count":26,"id":"8856c2c9","metadata":{"execution":{"iopub.execute_input":"2024-11-06T14:55:15.866842Z","iopub.status.busy":"2024-11-06T14:55:15.866505Z","iopub.status.idle":"2024-11-06T14:55:15.870819Z","shell.execute_reply":"2024-11-06T14:55:15.869969Z"},"papermill":{"duration":0.039367,"end_time":"2024-11-06T14:55:15.872864","exception":false,"start_time":"2024-11-06T14:55:15.833497","status":"completed"},"tags":[]},"outputs":[],"source":["os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # To avoid warnings"]},{"cell_type":"code","execution_count":27,"id":"6b527574","metadata":{"execution":{"iopub.execute_input":"2024-11-06T14:55:15.937541Z","iopub.status.busy":"2024-11-06T14:55:15.93727Z","iopub.status.idle":"2024-11-06T15:49:33.874263Z","shell.execute_reply":"2024-11-06T15:49:33.873021Z"},"papermill":{"duration":3257.972893,"end_time":"2024-11-06T15:49:33.877085","exception":false,"start_time":"2024-11-06T14:55:15.904192","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["[2024-11-06 14:55:27,064] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\r\n","[2024-11-06 14:55:27,069] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\r\n","/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\r\n","  warnings.warn(\r\n","/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\r\n","  warnings.warn(\r\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\r\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n","[2024-11-06 14:56:29,141] [INFO] [logging.py:129:log_dist] [Rank -1] DeepSpeed info: version=0.15.3, git-hash=unknown, git-branch=unknown\r\n","[2024-11-06 14:56:29,141] [INFO] [comm.py:652:init_distributed] cdb=None\r\n","[2024-11-06 14:56:29,141] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\r\n","[2024-11-06 14:56:29,148] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2\r\n","[2024-11-06 14:56:29,148] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead\r\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\r\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n","[2024-11-06 14:56:29,772] [INFO] [logging.py:129:log_dist] [Rank -1] DeepSpeed info: version=0.15.3, git-hash=unknown, git-branch=unknown\r\n","[2024-11-06 14:56:29,772] [INFO] [comm.py:652:init_distributed] cdb=None\r\n","[2024-11-06 14:56:29,776] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2\r\n","[2024-11-06 14:56:29,776] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead\r\n","[2024-11-06 14:56:30,627] [INFO] [logging.py:129:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: True\r\n","Using /root/.cache/torch_extensions/py310_cu123 as PyTorch extensions root...\r\n","Creating extension directory /root/.cache/torch_extensions/py310_cu123/cpu_adam...\r\n","Using /root/.cache/torch_extensions/py310_cu123 as PyTorch extensions root...\r\n","Emitting ninja build file /root/.cache/torch_extensions/py310_cu123/cpu_adam/build.ninja...\r\n","Building extension module cpu_adam...\r\n","Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\r\n","[1/3] c++ -MMD -MF cpu_adam.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -I/opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/usr/local/cuda/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX512__ -D__ENABLE_CUDA__ -c /opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/cpu_adam.cpp -o cpu_adam.o \r\n","[2/3] c++ -MMD -MF cpu_adam_impl.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -I/opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/usr/local/cuda/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX512__ -D__ENABLE_CUDA__ -c /opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/cpu_adam_impl.cpp -o cpu_adam_impl.o \r\n","[3/3] c++ cpu_adam.o cpu_adam_impl.o -shared -lcurand -L/usr/local/cuda/lib64 -L/opt/conda/lib/python3.10/site-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o cpu_adam.so\r\n","Loading extension module cpu_adam...\r\n","Time to load cpu_adam op: 43.600708961486816 seconds\r\n","Adam Optimizer #0 is created with AVX512 arithmetic capability.\r\n","Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\r\n","[2024-11-06 14:57:15,467] [INFO] [logging.py:129:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\r\n","[2024-11-06 14:57:15,467] [INFO] [logging.py:129:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\r\n","[2024-11-06 14:57:15,478] [INFO] [logging.py:129:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\r\n","[2024-11-06 14:57:15,478] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\r\n","[2024-11-06 14:57:15,479] [INFO] [logging.py:129:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\r\n","[2024-11-06 14:57:15,479] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000\r\n","[2024-11-06 14:57:15,479] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 500000000\r\n","[2024-11-06 14:57:15,479] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: True\r\n","[2024-11-06 14:57:15,479] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\r\n","Loading extension module cpu_adam...\r\n","Time to load cpu_adam op: 43.61045575141907 seconds\r\n","Adam Optimizer #0 is created with AVX512 arithmetic capability.\r\n","Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\r\n","[2024-11-06 14:57:16,562] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states\r\n","[2024-11-06 14:57:16,563] [INFO] [utils.py:782:see_memory_usage] MA 0.25 GB         Max_MA 0.25 GB         CA 0.25 GB         Max_CA 0 GB \r\n","[2024-11-06 14:57:16,563] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 15.0 GB, percent = 47.8%\r\n","[2024-11-06 14:57:16,663] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started\r\n","[2024-11-06 14:57:16,887] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states\r\n","[2024-11-06 14:57:16,888] [INFO] [utils.py:782:see_memory_usage] MA 0.25 GB         Max_MA 0.25 GB         CA 0.25 GB         Max_CA 0 GB \r\n","[2024-11-06 14:57:16,888] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 15.38 GB, percent = 49.0%\r\n","[2024-11-06 14:57:16,889] [INFO] [stage_1_and_2.py:544:__init__] optimizer state initialized\r\n","[2024-11-06 14:57:17,062] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer\r\n","[2024-11-06 14:57:17,064] [INFO] [utils.py:782:see_memory_usage] MA 0.25 GB         Max_MA 0.25 GB         CA 0.25 GB         Max_CA 0 GB \r\n","[2024-11-06 14:57:17,064] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 15.45 GB, percent = 49.3%\r\n","[2024-11-06 14:57:17,069] [INFO] [logging.py:129:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer\r\n","[2024-11-06 14:57:17,069] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started\r\n","[2024-11-06 14:57:17,069] [INFO] [logging.py:129:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupLR\r\n","[2024-11-06 14:57:17,069] [INFO] [logging.py:129:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7c849e7f6200>\r\n","[2024-11-06 14:57:17,069] [INFO] [logging.py:129:log_dist] [Rank 0] step=0, skipped=0, lr=[0], mom=[[0.9, 0.999]]\r\n","[2024-11-06 14:57:17,071] [INFO] [config.py:999:print] DeepSpeedEngine configuration:\r\n","[2024-11-06 14:57:17,071] [INFO] [config.py:1003:print]   activation_checkpointing_config  {\r\n","    \"partition_activations\": false, \r\n","    \"contiguous_memory_optimization\": false, \r\n","    \"cpu_checkpointing\": false, \r\n","    \"number_checkpoints\": null, \r\n","    \"synchronize_checkpoint_boundary\": false, \r\n","    \"profile\": false\r\n","}\r\n","[2024-11-06 14:57:17,071] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}\r\n","[2024-11-06 14:57:17,071] [INFO] [config.py:1003:print]   amp_enabled .................. False\r\n","[2024-11-06 14:57:17,071] [INFO] [config.py:1003:print]   amp_params ................... False\r\n","[2024-11-06 14:57:17,072] [INFO] [config.py:1003:print]   autotuning_config ............ {\r\n","    \"enabled\": true, \r\n","    \"start_step\": null, \r\n","    \"end_step\": null, \r\n","    \"metric_path\": null, \r\n","    \"arg_mappings\": {\r\n","        \"train_micro_batch_size_per_gpu\": \"--per_device_train_batch_size\", \r\n","        \"gradient_accumulation_steps\": \"--gradient_accumulation_steps\"\r\n","    }, \r\n","    \"metric\": \"throughput\", \r\n","    \"model_info\": null, \r\n","    \"results_dir\": \"autotuning_results\", \r\n","    \"exps_dir\": \"autotuning_exps\", \r\n","    \"overwrite\": true, \r\n","    \"fast\": true, \r\n","    \"start_profile_step\": 3, \r\n","    \"end_profile_step\": 5, \r\n","    \"tuner_type\": \"gridsearch\", \r\n","    \"tuner_early_stopping\": 5, \r\n","    \"tuner_num_trials\": 50, \r\n","    \"model_info_path\": null, \r\n","    \"mp_size\": 1, \r\n","    \"max_train_batch_size\": null, \r\n","    \"min_train_batch_size\": 1, \r\n","    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \r\n","    \"min_train_micro_batch_size_per_gpu\": 1, \r\n","    \"num_tuning_micro_batch_sizes\": 3\r\n","}\r\n","[2024-11-06 14:57:17,072] [INFO] [config.py:1003:print]   bfloat16_enabled ............. False\r\n","[2024-11-06 14:57:17,072] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False\r\n","[2024-11-06 14:57:17,072] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False\r\n","[2024-11-06 14:57:17,072] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True\r\n","[2024-11-06 14:57:17,072] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False\r\n","[2024-11-06 14:57:17,072] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7c849e7f5090>\r\n","[2024-11-06 14:57:17,072] [INFO] [config.py:1003:print]   communication_data_type ...... None\r\n","[2024-11-06 14:57:17,072] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\r\n","[2024-11-06 14:57:17,072] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False\r\n","[2024-11-06 14:57:17,072] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   disable_allgather ............ False\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   dump_state ................... False\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 1000, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   elasticity_enabled ........... False\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   flops_profiler_config ........ {\r\n","    \"enabled\": false, \r\n","    \"recompute_fwd_factor\": 0.0, \r\n","    \"profile_step\": 1, \r\n","    \"module_depth\": -1, \r\n","    \"top_modules\": 1, \r\n","    \"detailed\": true, \r\n","    \"output_file\": null\r\n","}\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   fp16_auto_cast ............... False\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   fp16_enabled ................. True\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   global_rank .................. 0\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 1\r\n","[2024-11-06 14:57:17,073] [INFO] [config.py:1003:print]   gradient_clipping ............ 1\r\n","[2024-11-06 14:57:17,074] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0\r\n","[2024-11-06 14:57:17,074] [INFO] [config.py:1003:print]   graph_harvesting ............. False\r\n","[2024-11-06 14:57:17,074] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\r\n","[2024-11-06 14:57:17,074] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 65536\r\n","[2024-11-06 14:57:17,074] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False\r\n","[2024-11-06 14:57:17,074] [INFO] [config.py:1003:print]   loss_scale ................... 0\r\n","[2024-11-06 14:57:17,074] [INFO] [config.py:1003:print]   memory_breakdown ............. False\r\n","[2024-11-06 14:57:17,074] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False\r\n","[2024-11-06 14:57:17,074] [INFO] [config.py:1003:print]   mics_shard_size .............. -1\r\n","[2024-11-06 14:57:17,074] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')\r\n","[2024-11-06 14:57:17,074] [INFO] [config.py:1003:print]   nebula_config ................ {\r\n","    \"enabled\": false, \r\n","    \"persistent_storage_path\": null, \r\n","    \"persistent_time_interval\": 100, \r\n","    \"num_of_version_in_retention\": 2, \r\n","    \"enable_nebula_load\": true, \r\n","    \"load_path\": null\r\n","}\r\n","[2024-11-06 14:57:17,074] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False\r\n","[2024-11-06 14:57:17,074] [INFO] [config.py:1003:print]   optimizer_name ............... adamw\r\n","[2024-11-06 14:57:17,074] [INFO] [config.py:1003:print]   optimizer_params ............. {'lr': 0.0001, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.01}\r\n","[2024-11-06 14:57:17,074] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\r\n","[2024-11-06 14:57:17,074] [INFO] [config.py:1003:print]   pld_enabled .................. False\r\n","[2024-11-06 14:57:17,074] [INFO] [config.py:1003:print]   pld_params ................... False\r\n","[2024-11-06 14:57:17,074] [INFO] [config.py:1003:print]   prescale_gradients ........... False\r\n","[2024-11-06 14:57:17,075] [INFO] [config.py:1003:print]   scheduler_name ............... WarmupLR\r\n","[2024-11-06 14:57:17,075] [INFO] [config.py:1003:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 0.001, 'warmup_num_steps': 1000}\r\n","[2024-11-06 14:57:17,075] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32\r\n","[2024-11-06 14:57:17,075] [INFO] [config.py:1003:print]   sparse_attention ............. None\r\n","[2024-11-06 14:57:17,075] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False\r\n","[2024-11-06 14:57:17,075] [INFO] [config.py:1003:print]   steps_per_print .............. 2000\r\n","[2024-11-06 14:57:17,075] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True\r\n","[2024-11-06 14:57:17,075] [INFO] [config.py:1003:print]   train_batch_size ............. 54\r\n","[2024-11-06 14:57:17,075] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  27\r\n","[2024-11-06 14:57:17,075] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False\r\n","[2024-11-06 14:57:17,075] [INFO] [config.py:1003:print]   use_node_local_storage ....... False\r\n","[2024-11-06 14:57:17,075] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False\r\n","[2024-11-06 14:57:17,075] [INFO] [config.py:1003:print]   weight_quantization_config ... None\r\n","[2024-11-06 14:57:17,075] [INFO] [config.py:1003:print]   world_size ................... 2\r\n","[2024-11-06 14:57:17,075] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  True\r\n","[2024-11-06 14:57:17,075] [INFO] [config.py:1003:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\r\n","[2024-11-06 14:57:17,075] [INFO] [config.py:1003:print]   zero_enabled ................. True\r\n","[2024-11-06 14:57:17,075] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True\r\n","[2024-11-06 14:57:17,075] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 2\r\n","[2024-11-06 14:57:17,076] [INFO] [config.py:989:print_user_config]   json = {\r\n","    \"train_batch_size\": 54, \r\n","    \"gradient_accumulation_steps\": 1, \r\n","    \"fp16\": {\r\n","        \"enabled\": true, \r\n","        \"min_loss_scale\": 1\r\n","    }, \r\n","    \"zero_optimization\": {\r\n","        \"stage\": 2, \r\n","        \"allgather_partitions\": true, \r\n","        \"reduce_scatter\": true, \r\n","        \"overlap_comm\": true, \r\n","        \"cpu_offload\": true\r\n","    }, \r\n","    \"autotuning\": {\r\n","        \"enabled\": true, \r\n","        \"arg_mappings\": {\r\n","            \"train_micro_batch_size_per_gpu\": \"--per_device_train_batch_size\", \r\n","            \"gradient_accumulation_steps\": \"--gradient_accumulation_steps\"\r\n","        }\r\n","    }, \r\n","    \"gradient_clipping\": 1, \r\n","    \"results_dir\": \"./autotuning_results\", \r\n","    \"exps_dir\": \"./autotuning_exps\", \r\n","    \"zero_allow_untested_optimizer\": true, \r\n","    \"steps_per_print\": 2.000000e+03, \r\n","    \"wall_clock_breakdown\": false, \r\n","    \"scheduler\": {\r\n","        \"type\": \"WarmupLR\", \r\n","        \"params\": {\r\n","            \"warmup_min_lr\": 0, \r\n","            \"warmup_max_lr\": 0.001, \r\n","            \"warmup_num_steps\": 1000\r\n","        }\r\n","    }, \r\n","    \"optimizer\": {\r\n","        \"type\": \"AdamW\", \r\n","        \"params\": {\r\n","            \"lr\": 0.0001, \r\n","            \"betas\": [0.9, 0.999], \r\n","            \"eps\": 1e-08, \r\n","            \"weight_decay\": 0.01\r\n","        }\r\n","    }\r\n","}\r\n","  0%|                                                   | 0/732 [00:00<?, ?it/s][2024-11-06 14:57:18,636] [INFO] [loss_scaler.py:190:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, but hysteresis is 2. Reducing hysteresis to 1\r\n","  0%|                                           | 1/732 [00:01<18:29,  1.52s/it][2024-11-06 14:57:19,709] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768\r\n","100%|█████████████████████████████████████████| 732/732 [17:14<00:00,  1.41s/it]\r\n","train_loss: 2.013864\r\n","Epoch 1 completed.\r\n","Epoch 1 completed.\r\n"," 40%|████████████████▍                        | 293/732 [06:27<10:28,  1.43s/it][2024-11-06 15:21:00,265] [INFO] [loss_scaler.py:190:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, but hysteresis is 2. Reducing hysteresis to 1\r\n"," 40%|████████████████▍                        | 294/732 [06:28<10:04,  1.38s/it][2024-11-06 15:21:01,511] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768\r\n","100%|█████████████████████████████████████████| 732/732 [17:29<00:00,  1.43s/it]\r\n","train_loss: 2.013113\r\n","Epoch 2 completed.\r\n","Epoch 2 completed.\r\n"," 78%|████████████████████████████████         | 573/732 [12:54<03:45,  1.42s/it][2024-11-06 15:44:56,582] [INFO] [loss_scaler.py:190:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, but hysteresis is 2. Reducing hysteresis to 1\r\n"," 78%|████████████████████████████████▏        | 574/732 [12:55<03:36,  1.37s/it][2024-11-06 15:44:57,804] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768\r\n","100%|█████████████████████████████████████████| 732/732 [17:28<00:00,  1.43s/it]\r\n","train_loss: 2.013912\r\n","Epoch 3 completed.\r\n","Epoch 3 completed.\r\n","Making Predictions:   0%|                            | 0/103 [00:00<?, ?batch/s]\r\n","[rank1]: Traceback (most recent call last):\r\n","[rank1]:   File \"/kaggle/working/train.py\", line 248, in <module>\r\n","[rank1]:     main()\r\n","[rank1]:   File \"/kaggle/working/train.py\", line 228, in main\r\n","[rank1]:     outputs = model(input_ids=input_ids, attention_mask=attention_mask)\r\n","[rank1]:   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\r\n","[rank1]:     return self._call_impl(*args, **kwargs)\r\n","[rank1]:   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\r\n","[rank1]:     return forward_call(*args, **kwargs)\r\n","[rank1]:   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py\", line 172, in forward\r\n","[rank1]:     raise RuntimeError(\"module must have its parameters and buffers \"\r\n","[rank1]: RuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cuda:1\r\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\r\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\r\n","W1106 15:49:32.455000 134425064740672 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 262 closing signal SIGTERM\r\n","E1106 15:49:33.070000 134425064740672 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 1 (pid: 263) of binary: /opt/conda/bin/python3.10\r\n","Traceback (most recent call last):\r\n","  File \"/opt/conda/bin/accelerate\", line 8, in <module>\r\n","    sys.exit(main())\r\n","  File \"/opt/conda/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\r\n","    args.func(args)\r\n","  File \"/opt/conda/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 1165, in launch_command\r\n","    multi_gpu_launcher(args)\r\n","  File \"/opt/conda/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 799, in multi_gpu_launcher\r\n","    distrib_run.run(args)\r\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/run.py\", line 892, in run\r\n","    elastic_launch(\r\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 133, in __call__\r\n","    return launch_agent(self._config, self._entrypoint, list(args))\r\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\r\n","    raise ChildFailedError(\r\n","torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n","============================================================\r\n","train.py FAILED\r\n","------------------------------------------------------------\r\n","Failures:\r\n","  <NO_OTHER_FAILURES>\r\n","------------------------------------------------------------\r\n","Root Cause (first observed failure):\r\n","[0]:\r\n","  time      : 2024-11-06_15:49:32\r\n","  host      : 4afaf162195e\r\n","  rank      : 1 (local_rank: 1)\r\n","  exitcode  : 1 (pid: 263)\r\n","  error_file: <N/A>\r\n","  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n","============================================================\r\n"]}],"source":["!accelerate launch train.py --precision fp16 # using fp16 mixed-precision"]},{"cell_type":"markdown","id":"b6af6cbd","metadata":{"papermill":{"duration":0.21733,"end_time":"2024-11-06T15:49:34.315949","exception":false,"start_time":"2024-11-06T15:49:34.098619","status":"completed"},"tags":[]},"source":["# Thank You ( Do upvote if you like this notebook)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5338273,"sourceId":8870083,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":3451.397253,"end_time":"2024-11-06T15:49:37.356346","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-11-06T14:52:05.959093","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"0448e7bbfabd4883a9edd389c008ae9e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b9dbf8c855c4b92b78fb27df568dcf7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d30506f57a64dd98440164beeb6a6fd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"133057c650fd4b5ca0d8e1a586d5b647":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13937f3fdb0044569bdf58848ac0ed1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"159f1db4674a42b08601d2544f702421":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f6e4f5baa5654d84bf42501b152eaa05","IPY_MODEL_2d55046f90554520b244a510fcd605de","IPY_MODEL_7e9bd305a4fe48e4b9d0694d1b870fe6"],"layout":"IPY_MODEL_6471dc1c293a4a66a6580c1122c48a79"}},"15db1c66cc3341c19b0884d6ddc28506":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"19300a10f3d74eb1893fa45cfa313870":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b2d075d651e4f44a7503ad984168f1e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d54cb1b83aa4906b6877155b63e3a59":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e4cf3c6c0fc40d19b48960bd7dae692":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fe9912e44bb4266961c1546b855e8db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2cd1f9ca5af4d18895482824d661e15","placeholder":"​","style":"IPY_MODEL_e40910482bb740d4bc301c9756b7ba59","value":"model.safetensors: 100%"}},"2d55046f90554520b244a510fcd605de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb3857fc6cc4446080af1fdcb27a43a1","max":231508.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_d7deea8c78684c9eba502e3e94e3b9f0","value":231508.0}},"2e1c08741d8a43e4bb8234d7692abb9a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1fe9912e44bb4266961c1546b855e8db","IPY_MODEL_7304675e0cf74533831c407ab1a388cf","IPY_MODEL_8f7df34e877643a9a19523341a500a14"],"layout":"IPY_MODEL_2ea5cf6dd33b4e9bbc2527ed003a1e04"}},"2ea5cf6dd33b4e9bbc2527ed003a1e04":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"313eff5225924f7ab5793423d21567ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e7bdaa1df924e09858e43c183393839":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4138d4e313a0491bb5febf18275b7a64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"446d62f8b11647408abbe324392b0aec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_df11cbb736b34cf299ea7f69b364fd98","IPY_MODEL_935df6c9d607481fb753c13fd0b79375","IPY_MODEL_67cbf77ca4774fb89915709242c71918"],"layout":"IPY_MODEL_5742ec2af24d4327a28900b3a1c396a7"}},"459e861abdb346e39902e0f34c1f11cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a88d24d4e2843b8b4a47195f7c138d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4cdccbba215a4d4bb264b7940d406876":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54c76176abb5426fa518a5ab067470e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d30506f57a64dd98440164beeb6a6fd","max":48.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_4a88d24d4e2843b8b4a47195f7c138d4","value":48.0}},"5742ec2af24d4327a28900b3a1c396a7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"604d4a16b5774e68a9fe27c921c1322e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7f5d955270a047b09776867dae0976bf","IPY_MODEL_54c76176abb5426fa518a5ab067470e1","IPY_MODEL_7fd8c7ce7fb54fd0919fd48bd02bf411"],"layout":"IPY_MODEL_b5c31f133557473483e8f7d6aa68efe1"}},"6471dc1c293a4a66a6580c1122c48a79":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67cbf77ca4774fb89915709242c71918":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e4cf3c6c0fc40d19b48960bd7dae692","placeholder":"​","style":"IPY_MODEL_4138d4e313a0491bb5febf18275b7a64","value":" 466k/466k [00:00&lt;00:00, 3.53MB/s]"}},"696a4b6497c04fc596f0ba74da8b54e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f497ea34dd6447cb7af4e191e1396a9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72dabce2f49d49d38eae92558d5c4784":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7304675e0cf74533831c407ab1a388cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e7bdaa1df924e09858e43c183393839","max":440449768.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_8999abf64b674ecabccfd51f0e6c49cb","value":440449768.0}},"7d097c797d304385b72b3e1d1d605d22":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e9bd305a4fe48e4b9d0694d1b870fe6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d097c797d304385b72b3e1d1d605d22","placeholder":"​","style":"IPY_MODEL_0b9dbf8c855c4b92b78fb27df568dcf7","value":" 232k/232k [00:00&lt;00:00, 1.75MB/s]"}},"7f5d955270a047b09776867dae0976bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_afbe9ce394bd492c863c4511df981569","placeholder":"​","style":"IPY_MODEL_459e861abdb346e39902e0f34c1f11cb","value":"tokenizer_config.json: 100%"}},"7fd8c7ce7fb54fd0919fd48bd02bf411":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b2d075d651e4f44a7503ad984168f1e","placeholder":"​","style":"IPY_MODEL_13937f3fdb0044569bdf58848ac0ed1a","value":" 48.0/48.0 [00:00&lt;00:00, 3.66kB/s]"}},"8999abf64b674ecabccfd51f0e6c49cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f7df34e877643a9a19523341a500a14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a47c6259cdf344489931474e64125e80","placeholder":"​","style":"IPY_MODEL_0448e7bbfabd4883a9edd389c008ae9e","value":" 440M/440M [00:01&lt;00:00, 239MB/s]"}},"935df6c9d607481fb753c13fd0b79375":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_72dabce2f49d49d38eae92558d5c4784","max":466062.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_15db1c66cc3341c19b0884d6ddc28506","value":466062.0}},"94106e2ae5cb407581976762f2b8f6be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f497ea34dd6447cb7af4e191e1396a9","max":570.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_f5664484ef3a4353a01597096d1eb42d","value":570.0}},"9c57d32169674d9e8cdca2157e974ae8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a47c6259cdf344489931474e64125e80":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a91793c8dc1745469c03b1e73f39a2ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af00bdb409d140cab016d49bd346d8af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_696a4b6497c04fc596f0ba74da8b54e4","placeholder":"​","style":"IPY_MODEL_fc4f787ef41344509bd1701075ce06a7","value":" 570/570 [00:00&lt;00:00, 43.3kB/s]"}},"afbe9ce394bd492c863c4511df981569":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2cd1f9ca5af4d18895482824d661e15":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5c31f133557473483e8f7d6aa68efe1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7deea8c78684c9eba502e3e94e3b9f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc27ea09f68b4b15b82699e33c95076c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a91793c8dc1745469c03b1e73f39a2ab","placeholder":"​","style":"IPY_MODEL_1d54cb1b83aa4906b6877155b63e3a59","value":"config.json: 100%"}},"df11cbb736b34cf299ea7f69b364fd98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19300a10f3d74eb1893fa45cfa313870","placeholder":"​","style":"IPY_MODEL_9c57d32169674d9e8cdca2157e974ae8","value":"tokenizer.json: 100%"}},"e40910482bb740d4bc301c9756b7ba59":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec5290d9e6f14452bdea90b2cce603b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc27ea09f68b4b15b82699e33c95076c","IPY_MODEL_94106e2ae5cb407581976762f2b8f6be","IPY_MODEL_af00bdb409d140cab016d49bd346d8af"],"layout":"IPY_MODEL_4cdccbba215a4d4bb264b7940d406876"}},"f5664484ef3a4353a01597096d1eb42d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f6e4f5baa5654d84bf42501b152eaa05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_313eff5225924f7ab5793423d21567ca","placeholder":"​","style":"IPY_MODEL_133057c650fd4b5ca0d8e1a586d5b647","value":"vocab.txt: 100%"}},"fb3857fc6cc4446080af1fdcb27a43a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc4f787ef41344509bd1701075ce06a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":5}