{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8870083,"sourceType":"datasetVersion","datasetId":5338273}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mahammadashad/mental-health-analysis-model?scriptVersionId=202196766\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## Mental Health Classification using Bert and Deepspeed <br>\n\n### In this model i have two parts \n#### 1. Untrained model without using Deepspeed \n#### 2. train.py file with traning script for Deepspeed training  <br>\n\n#### Why i have two parts , its because i have all the preprocessing visualization and other components explained in this notebook so it's easier to understand.\n#### In the train.py file i have not explained much so i include the first part. \n\n#####  Hope this will be of some use , Thank You","metadata":{"_uuid":"6e12c425-366e-4ede-9b4e-4d616dac7a46","_cell_guid":"eb1bf72a-1b50-46bb-9ead-810dd540f7cf","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-15T14:50:52.47719Z","iopub.execute_input":"2024-10-15T14:50:52.477972Z","iopub.status.idle":"2024-10-15T14:50:57.537989Z","shell.execute_reply.started":"2024-10-15T14:50:52.477921Z","shell.execute_reply":"2024-10-15T14:50:57.536964Z"}}},{"cell_type":"code","source":"\nimport pandas as pd\nimport re\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer\nimport torch\nfrom torch.utils.data import DataLoader\nfrom transformers import BertModel,BertTokenizerFast,BertForSequenceClassification, Adafactor\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-10-20T05:34:40.826965Z","iopub.execute_input":"2024-10-20T05:34:40.827374Z","iopub.status.idle":"2024-10-20T05:34:40.832899Z","shell.execute_reply.started":"2024-10-20T05:34:40.827335Z","shell.execute_reply":"2024-10-20T05:34:40.83195Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/sentiment-analysis-for-mental-health/Combined Data.csv\")","metadata":{"_uuid":"e1e57aa8-4a49-434b-971a-874d01889511","_cell_guid":"5ee42e11-6bf6-4db6-8666-e18061bb9582","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T05:34:41.786157Z","iopub.execute_input":"2024-10-20T05:34:41.786551Z","iopub.status.idle":"2024-10-20T05:34:42.169007Z","shell.execute_reply.started":"2024-10-20T05:34:41.786513Z","shell.execute_reply":"2024-10-20T05:34:42.167952Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"_uuid":"518758d4-1a69-4693-9865-c1e486e24ba8","_cell_guid":"909efe06-2a32-43c2-ad3e-5831eb521206","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T05:34:42.183403Z","iopub.execute_input":"2024-10-20T05:34:42.183746Z","iopub.status.idle":"2024-10-20T05:34:42.19778Z","shell.execute_reply.started":"2024-10-20T05:34:42.183714Z","shell.execute_reply":"2024-10-20T05:34:42.196749Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"       Unnamed: 0  \\\n0               0   \n1               1   \n2               2   \n3               3   \n4               4   \n...           ...   \n53038       53038   \n53039       53039   \n53040       53040   \n53041       53041   \n53042       53042   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          statement  \\\n0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        oh my gosh   \n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  trouble sleeping, confused mind, restless heart. All out of tune   \n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    All wrong, back off dear, forward doubt. Stay in a restless and restless place   \n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     I've shifted my focus to something else but I'm still worried   \n4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          I'm restless and restless, it's been a month now, boy. What do you mean?   \n...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ...   \n53038  Nobody takes me seriously I’ve (24M) dealt with depression/anxiety for years now. I used to be great with people, make good money, have the nice cars, great girlfriend, supportive parents, friends that I could say looked up to me etc. and then I was diagnosed with depression. Within about a year, I quit my job, lost my girlfriend even though she was great to me, and have yet to keep a stable job for more than a month at a time. \\n\\nMy depression eventually was ruled to be “treatment resistant” after being on a number of meds and trying many other things. Some would work for a couple months and then I’d fall even further back from where I was. \\n\\nBut now, after not having worked since early July of 2022, I am dealing with extensive and scary brain fog. I’ve incorporated working out, eating healthier, taking supplements and just trying to live a healthier lifestyle as I figured this was coming from a bad diet my whole life. I also got all blood work done including thyroid, basics, vitamin levels, testosterone etc and everything came back normal other than pretty high cholesterol. Both doctors I’ve seen (general practitioner, psychiatrist) has kinda blown me off when I tell them about the brain fog. Almost like they don’t really know what to say or what the next step should be to ruling out causes. \\n\\nI’m so scared as I’m feeling like I’m going crazy or have dementia. My parents are usually very supportive when I’m going through stuff but my mom doesn’t even want to hear me talk about it and my dad isn’t always around as he lives about 45 mins away. I ended up packing some things and driving to his house tonight without saying anything to my mom. I just hate feeling alone and don’t know what to do anymore. I feel like I’m at the end of my road   \n53039                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        selfishness  \"I don't feel very good, it's like I don't belong in this world (I don't think I ever did). My friends are happy, and I'm always the one who's not really funny and who ruins the mood. So now I try to say as little as possible, people always ask me if I'm okay, if I'm tired, or worse, they say I'm scary. I think I'm just a mistake. People must find me weird or creepy, it's ruining me. A few years ago, my brother committed suicide, I felt very close to him, I think about his death all the time, I wish I could start my life over again and make the right choices (for once). What affects me the most is girls, I think... It's ridiculous, but I would love to have a relationship with a (very) pretty girl. Sometimes I think I've suffered so much that I would at least deserve that. I saw the damage my brother's death caused in my family, now I think if I didn't have a family to make suffer =&gt; suicide. My message is so selfish, and I know it. Thank you for reading these few lines...\" \\n\\n\\-Lust   \n53040                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Is there any way to sleep better? I can't sleep most of the nights, meds didn't help.   \n53041                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Public speaking tips? Hi, all. I have to give a presentation at work next week (45 minutes long and the CEO will be in attendance). I’m already panicking, as once the anxiety kicks in, I’m certain I’m going to forget everything I’m supposed to say. ( anxiety makes it very difficult for me to focus on anything) Does anyone have any speaking tips that have worked for them in the past? Thanks so much!   \n53042                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             I have really bad door anxiety! It's not about being scared I didn't lock the door or something, I'm just really scared of opening doors the wrong way or turning a key the wrong way in front of people or pushing instead of pulling and viceversa, it's honestly debilitating because i feel like I'm gonna die everytime I have to open a door. I wondered if anyone else has the same problem and how to fix it if possible.   \n\n        status  \n0      Anxiety  \n1      Anxiety  \n2      Anxiety  \n3      Anxiety  \n4      Anxiety  \n...        ...  \n53038  Anxiety  \n53039  Anxiety  \n53040  Anxiety  \n53041  Anxiety  \n53042  Anxiety  \n\n[53043 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>statement</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>oh my gosh</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>trouble sleeping, confused mind, restless heart. All out of tune</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>All wrong, back off dear, forward doubt. Stay in a restless and restless place</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>I've shifted my focus to something else but I'm still worried</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>I'm restless and restless, it's been a month now, boy. What do you mean?</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>53038</th>\n      <td>53038</td>\n      <td>Nobody takes me seriously I’ve (24M) dealt with depression/anxiety for years now. I used to be great with people, make good money, have the nice cars, great girlfriend, supportive parents, friends that I could say looked up to me etc. and then I was diagnosed with depression. Within about a year, I quit my job, lost my girlfriend even though she was great to me, and have yet to keep a stable job for more than a month at a time. \\n\\nMy depression eventually was ruled to be “treatment resistant” after being on a number of meds and trying many other things. Some would work for a couple months and then I’d fall even further back from where I was. \\n\\nBut now, after not having worked since early July of 2022, I am dealing with extensive and scary brain fog. I’ve incorporated working out, eating healthier, taking supplements and just trying to live a healthier lifestyle as I figured this was coming from a bad diet my whole life. I also got all blood work done including thyroid, basics, vitamin levels, testosterone etc and everything came back normal other than pretty high cholesterol. Both doctors I’ve seen (general practitioner, psychiatrist) has kinda blown me off when I tell them about the brain fog. Almost like they don’t really know what to say or what the next step should be to ruling out causes. \\n\\nI’m so scared as I’m feeling like I’m going crazy or have dementia. My parents are usually very supportive when I’m going through stuff but my mom doesn’t even want to hear me talk about it and my dad isn’t always around as he lives about 45 mins away. I ended up packing some things and driving to his house tonight without saying anything to my mom. I just hate feeling alone and don’t know what to do anymore. I feel like I’m at the end of my road</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>53039</th>\n      <td>53039</td>\n      <td>selfishness  \"I don't feel very good, it's like I don't belong in this world (I don't think I ever did). My friends are happy, and I'm always the one who's not really funny and who ruins the mood. So now I try to say as little as possible, people always ask me if I'm okay, if I'm tired, or worse, they say I'm scary. I think I'm just a mistake. People must find me weird or creepy, it's ruining me. A few years ago, my brother committed suicide, I felt very close to him, I think about his death all the time, I wish I could start my life over again and make the right choices (for once). What affects me the most is girls, I think... It's ridiculous, but I would love to have a relationship with a (very) pretty girl. Sometimes I think I've suffered so much that I would at least deserve that. I saw the damage my brother's death caused in my family, now I think if I didn't have a family to make suffer =&amp;gt; suicide. My message is so selfish, and I know it. Thank you for reading these few lines...\" \\n\\n\\-Lust</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>53040</th>\n      <td>53040</td>\n      <td>Is there any way to sleep better? I can't sleep most of the nights, meds didn't help.</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>53041</th>\n      <td>53041</td>\n      <td>Public speaking tips? Hi, all. I have to give a presentation at work next week (45 minutes long and the CEO will be in attendance). I’m already panicking, as once the anxiety kicks in, I’m certain I’m going to forget everything I’m supposed to say. ( anxiety makes it very difficult for me to focus on anything) Does anyone have any speaking tips that have worked for them in the past? Thanks so much!</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>53042</th>\n      <td>53042</td>\n      <td>I have really bad door anxiety! It's not about being scared I didn't lock the door or something, I'm just really scared of opening doors the wrong way or turning a key the wrong way in front of people or pushing instead of pulling and viceversa, it's honestly debilitating because i feel like I'm gonna die everytime I have to open a door. I wondered if anyone else has the same problem and how to fix it if possible.</td>\n      <td>Anxiety</td>\n    </tr>\n  </tbody>\n</table>\n<p>53043 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.info()","metadata":{"_uuid":"12646d36-de53-4c2d-89c7-adf304c7c53c","_cell_guid":"e7bf0855-a72d-4c83-b57e-886836f09dda","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T05:34:42.430821Z","iopub.execute_input":"2024-10-20T05:34:42.431547Z","iopub.status.idle":"2024-10-20T05:34:42.455963Z","shell.execute_reply.started":"2024-10-20T05:34:42.431495Z","shell.execute_reply":"2024-10-20T05:34:42.454748Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 53043 entries, 0 to 53042\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   Unnamed: 0  53043 non-null  int64 \n 1   statement   52681 non-null  object\n 2   status      53043 non-null  object\ndtypes: int64(1), object(2)\nmemory usage: 1.2+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"# Displaying the full length\npd.set_option('display.max_colwidth', None)\ndf.head()\n","metadata":{"_uuid":"67ef0611-a1f0-46f7-a1d2-b86c3e1bf61c","_cell_guid":"8b80baef-ce6e-4644-8557-40736ddc67cb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T05:34:42.662917Z","iopub.execute_input":"2024-10-20T05:34:42.663588Z","iopub.status.idle":"2024-10-20T05:34:42.674796Z","shell.execute_reply.started":"2024-10-20T05:34:42.663543Z","shell.execute_reply":"2024-10-20T05:34:42.67373Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0  \\\n0           0   \n1           1   \n2           2   \n3           3   \n4           4   \n\n                                                                        statement  \\\n0                                                                      oh my gosh   \n1                trouble sleeping, confused mind, restless heart. All out of tune   \n2  All wrong, back off dear, forward doubt. Stay in a restless and restless place   \n3                   I've shifted my focus to something else but I'm still worried   \n4        I'm restless and restless, it's been a month now, boy. What do you mean?   \n\n    status  \n0  Anxiety  \n1  Anxiety  \n2  Anxiety  \n3  Anxiety  \n4  Anxiety  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>statement</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>oh my gosh</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>trouble sleeping, confused mind, restless heart. All out of tune</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>All wrong, back off dear, forward doubt. Stay in a restless and restless place</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>I've shifted my focus to something else but I'm still worried</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>I'm restless and restless, it's been a month now, boy. What do you mean?</td>\n      <td>Anxiety</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Checking for null values","metadata":{"_uuid":"723dd87d-5fdd-4423-ab7e-3b1d0776e3dc","_cell_guid":"a9096e61-4d8e-4f06-bb2d-77d55ea989a3","trusted":true}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"_uuid":"179966ee-da3b-4344-ad7e-d654423f6d6b","_cell_guid":"0aab04e7-7958-4499-8c2a-7b608c04922a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T05:34:43.214988Z","iopub.execute_input":"2024-10-20T05:34:43.21601Z","iopub.status.idle":"2024-10-20T05:34:43.236677Z","shell.execute_reply.started":"2024-10-20T05:34:43.215967Z","shell.execute_reply":"2024-10-20T05:34:43.23549Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"Unnamed: 0      0\nstatement     362\nstatus          0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"#Removing Null Values\ndf.dropna(inplace=True)","metadata":{"_uuid":"8daed9c5-00e9-4543-97e9-82f1e601bb16","_cell_guid":"21e41fc0-9d51-49a8-bad3-1ba350eb60f6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T05:34:43.496723Z","iopub.execute_input":"2024-10-20T05:34:43.497131Z","iopub.status.idle":"2024-10-20T05:34:43.51926Z","shell.execute_reply.started":"2024-10-20T05:34:43.497094Z","shell.execute_reply":"2024-10-20T05:34:43.518108Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"_uuid":"379a58b2-3aa5-495a-9c9b-3d5407db516e","_cell_guid":"3fc1626c-2d8b-49fe-8643-0298135f2d45","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T05:34:44.021045Z","iopub.execute_input":"2024-10-20T05:34:44.021474Z","iopub.status.idle":"2024-10-20T05:34:44.042316Z","shell.execute_reply.started":"2024-10-20T05:34:44.021438Z","shell.execute_reply":"2024-10-20T05:34:44.041267Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"Unnamed: 0    0\nstatement     0\nstatus        0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Converting 'statement' to column to string for using it in BERTokenizer\n\ndf[\"str_statement\"]= df[\"statement\"].astype(str)","metadata":{"_uuid":"f3365897-89b1-4763-aead-d820c38e4cec","_cell_guid":"b9c4b366-46c9-4684-9add-30974f0a9a23","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T05:34:44.34682Z","iopub.execute_input":"2024-10-20T05:34:44.3472Z","iopub.status.idle":"2024-10-20T05:34:44.355121Z","shell.execute_reply.started":"2024-10-20T05:34:44.347166Z","shell.execute_reply":"2024-10-20T05:34:44.354147Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"df[\"str_statement\"].head()","metadata":{"_uuid":"062642f7-8194-4d5b-befa-153f69b86dbd","_cell_guid":"620156b4-8cbe-4891-b501-1895c3439b64","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T05:34:44.692197Z","iopub.execute_input":"2024-10-20T05:34:44.692571Z","iopub.status.idle":"2024-10-20T05:34:44.700969Z","shell.execute_reply.started":"2024-10-20T05:34:44.692534Z","shell.execute_reply":"2024-10-20T05:34:44.69982Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"0                                                                        oh my gosh\n1                  trouble sleeping, confused mind, restless heart. All out of tune\n2    All wrong, back off dear, forward doubt. Stay in a restless and restless place\n3                     I've shifted my focus to something else but I'm still worried\n4          I'm restless and restless, it's been a month now, boy. What do you mean?\nName: str_statement, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"# Covert to lowercase","metadata":{"_uuid":"d53fd78d-8876-47dd-a64d-59381fec52e8","_cell_guid":"a8afa27a-f5ad-4eb7-8269-8e4782e732e8","trusted":true}},{"cell_type":"code","source":"df['str_statement'] = df['statement'].str.lower()","metadata":{"_uuid":"dc6f518c-e7f1-466f-a4d6-6ca5d8b518a0","_cell_guid":"0be010d2-f33d-4c07-a631-ef6aee1e0b2e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T05:34:45.341045Z","iopub.execute_input":"2024-10-20T05:34:45.341809Z","iopub.status.idle":"2024-10-20T05:34:45.438597Z","shell.execute_reply.started":"2024-10-20T05:34:45.34176Z","shell.execute_reply":"2024-10-20T05:34:45.437553Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"df[\"str_statement\"].head()","metadata":{"_uuid":"c7489b83-e466-4c74-babf-de828412b204","_cell_guid":"b72dc993-cf4c-46bf-8815-b21a9d9465e9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T05:34:45.786747Z","iopub.execute_input":"2024-10-20T05:34:45.787347Z","iopub.status.idle":"2024-10-20T05:34:45.794791Z","shell.execute_reply.started":"2024-10-20T05:34:45.787307Z","shell.execute_reply":"2024-10-20T05:34:45.793875Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"0                                                                        oh my gosh\n1                  trouble sleeping, confused mind, restless heart. all out of tune\n2    all wrong, back off dear, forward doubt. stay in a restless and restless place\n3                     i've shifted my focus to something else but i'm still worried\n4          i'm restless and restless, it's been a month now, boy. what do you mean?\nName: str_statement, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"# Remove links and unwanted things like username,links etc","metadata":{"_uuid":"49f45c8a-6ca5-441f-b7dd-644127d4c03b","_cell_guid":"5e91ffb6-655e-4b0f-87c2-3d9fdce6aadd","trusted":true}},{"cell_type":"code","source":"def remove_patterns(text):\n    # URL Removal\n    text = re.sub(r'http[s]?://\\S+','',text)\n    # Remove markdown style links\n    text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)\n    # Remove handles (that start with '@')\n    text = re.sub(r'@\\w+', '', text)\n    # Remove punctuation and other special characters\n    text = re.sub(r'[^\\w\\s]', '', text)\n    return text.strip()\n    \ndf['str_statement'] = df['str_statement'].apply(remove_patterns)\ndf.head()","metadata":{"_uuid":"fc4ebe04-6acc-4525-8e3e-8433ce1f8fb7","_cell_guid":"37e0b7fe-bcae-4691-b572-5102f99ceb4c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T05:34:47.10688Z","iopub.execute_input":"2024-10-20T05:34:47.107288Z","iopub.status.idle":"2024-10-20T05:34:48.613016Z","shell.execute_reply.started":"2024-10-20T05:34:47.107251Z","shell.execute_reply":"2024-10-20T05:34:48.612031Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0  \\\n0           0   \n1           1   \n2           2   \n3           3   \n4           4   \n\n                                                                        statement  \\\n0                                                                      oh my gosh   \n1                trouble sleeping, confused mind, restless heart. All out of tune   \n2  All wrong, back off dear, forward doubt. Stay in a restless and restless place   \n3                   I've shifted my focus to something else but I'm still worried   \n4        I'm restless and restless, it's been a month now, boy. What do you mean?   \n\n    status  \\\n0  Anxiety   \n1  Anxiety   \n2  Anxiety   \n3  Anxiety   \n4  Anxiety   \n\n                                                                 str_statement  \n0                                                                   oh my gosh  \n1                trouble sleeping confused mind restless heart all out of tune  \n2  all wrong back off dear forward doubt stay in a restless and restless place  \n3                  ive shifted my focus to something else but im still worried  \n4           im restless and restless its been a month now boy what do you mean  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>statement</th>\n      <th>status</th>\n      <th>str_statement</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>oh my gosh</td>\n      <td>Anxiety</td>\n      <td>oh my gosh</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>trouble sleeping, confused mind, restless heart. All out of tune</td>\n      <td>Anxiety</td>\n      <td>trouble sleeping confused mind restless heart all out of tune</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>All wrong, back off dear, forward doubt. Stay in a restless and restless place</td>\n      <td>Anxiety</td>\n      <td>all wrong back off dear forward doubt stay in a restless and restless place</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>I've shifted my focus to something else but I'm still worried</td>\n      <td>Anxiety</td>\n      <td>ive shifted my focus to something else but im still worried</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>I'm restless and restless, it's been a month now, boy. What do you mean?</td>\n      <td>Anxiety</td>\n      <td>im restless and restless its been a month now boy what do you mean</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Convert the labels (strings) to integers using Label Encoder","metadata":{"_uuid":"72eeb653-5155-432e-9499-a2bb7872025b","_cell_guid":"ee0c145b-6768-41a6-be92-341bedfea77c","trusted":true}},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ndf['encoded_status'] = label_encoder.fit_transform(df['status'])","metadata":{"_uuid":"578d5327-cc12-479e-858b-09f3b4348341","_cell_guid":"18d50e00-5fe8-4325-bcb6-4b4eab44f579","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T05:36:17.861288Z","iopub.execute_input":"2024-10-20T05:36:17.862173Z","iopub.status.idle":"2024-10-20T05:36:17.879785Z","shell.execute_reply.started":"2024-10-20T05:36:17.862129Z","shell.execute_reply":"2024-10-20T05:36:17.878562Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# Splitting the data and Tokenzation using BertTokenizerFast","metadata":{"_uuid":"79e07f4a-c063-4a88-86bc-bb823e4a9480","_cell_guid":"2fbb9c36-dd77-4dc4-b2f4-2fb05ef26de5","execution":{"iopub.status.busy":"2024-09-26T13:04:47.193597Z","iopub.execute_input":"2024-09-26T13:04:47.194453Z","iopub.status.idle":"2024-09-26T13:04:47.198183Z","shell.execute_reply.started":"2024-09-26T13:04:47.194411Z","shell.execute_reply":"2024-09-26T13:04:47.197378Z"},"trusted":true}},{"cell_type":"code","source":"# Initialize the tokenizer for the pre-trained BERT model\ntokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2024-10-20T05:34:48.823872Z","iopub.execute_input":"2024-10-20T05:34:48.824222Z","iopub.status.idle":"2024-10-20T05:34:48.932957Z","shell.execute_reply.started":"2024-10-20T05:34:48.824187Z","shell.execute_reply":"2024-10-20T05:34:48.93203Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Split the dataset into training and validation sets","metadata":{"execution":{"iopub.status.busy":"2024-10-15T14:48:26.61159Z","iopub.execute_input":"2024-10-15T14:48:26.612613Z","iopub.status.idle":"2024-10-15T14:48:26.617671Z","shell.execute_reply.started":"2024-10-15T14:48:26.612543Z","shell.execute_reply":"2024-10-15T14:48:26.616589Z"}}},{"cell_type":"code","source":"train_texts, val_texts, train_labels, val_labels = train_test_split(\n    df['str_statement'],  \n    df['encoded_status'],\n    test_size=0.25, # Here 25 percent of the dat will be used for validation\n    random_state=42\n)","metadata":{"_uuid":"01c48a3d-7065-417c-bf12-32f335a32035","_cell_guid":"17fc04ce-f6ab-4753-889b-b529943d503c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T05:36:46.742019Z","iopub.execute_input":"2024-10-20T05:36:46.74244Z","iopub.status.idle":"2024-10-20T05:36:46.758755Z","shell.execute_reply.started":"2024-10-20T05:36:46.742403Z","shell.execute_reply":"2024-10-20T05:36:46.757804Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# Tokenization using BERTTokenizerFAst\n\nmax_length= 512\ntrain_encodings= tokenizer(train_texts.tolist(),padding='max_length',truncation=True,return_tensors='pt') # Here it will return the tokens as tensors\nval_encodings =tokenizer(val_texts.tolist(),padding='max_length',truncation=True,return_tensors='pt')","metadata":{"_uuid":"ff444186-5f35-4a1d-a978-b564d427e374","_cell_guid":"1c63c8d9-8045-4eb2-9b6d-5a2a79eb0bc9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T05:37:02.541137Z","iopub.execute_input":"2024-10-20T05:37:02.541524Z","iopub.status.idle":"2024-10-20T05:37:42.637629Z","shell.execute_reply.started":"2024-10-20T05:37:02.541488Z","shell.execute_reply":"2024-10-20T05:37:42.636517Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"# Convert the tokenized encodings to a PyTorch dataset","metadata":{"_uuid":"61175f93-d1aa-43a4-9af6-2e6722d3c04a","_cell_guid":"3b37c7dc-6cc5-4388-be58-35b8bede3d95","trusted":true}},{"cell_type":"code","source":"import torch\n\nclass MentalHealthDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = torch.tensor(labels)\n\n    def __getitem__(self, idx):\n        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n        item['labels'] = self.labels[idx].clone().detach()\n\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# Create the datasets\ntrain_dataset = MentalHealthDataset(train_encodings, train_labels.tolist()) # You need to convert it to list \nval_dataset = MentalHealthDataset(val_encodings, val_labels.tolist()) # You need to convert it to list ","metadata":{"_uuid":"54d14db9-23a7-4977-8dc0-812b85a5ded7","_cell_guid":"e311e84d-fae9-4a78-a8b6-fb8ffc0d566b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T05:38:11.75695Z","iopub.execute_input":"2024-10-20T05:38:11.757874Z","iopub.status.idle":"2024-10-20T05:38:11.783583Z","shell.execute_reply.started":"2024-10-20T05:38:11.75783Z","shell.execute_reply":"2024-10-20T05:38:11.782637Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Create DataLoader for both training and validation datasets\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,num_workers=2) # You can change batch size as per your need\nval_loader = DataLoader(val_dataset,  batch_size=32)","metadata":{"_uuid":"ff5eff96-ad0a-4a6e-835d-8003bf3b8864","_cell_guid":"71ab5a01-0c33-4c40-8798-2b4e024f0209","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T05:38:12.183553Z","iopub.execute_input":"2024-10-20T05:38:12.184231Z","iopub.status.idle":"2024-10-20T05:38:12.465864Z","shell.execute_reply.started":"2024-10-20T05:38:12.184187Z","shell.execute_reply":"2024-10-20T05:38:12.464772Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"Initializing ","metadata":{}},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=7) ","metadata":{"_uuid":"06d65886-7c76-490a-832c-26b0e5e48392","_cell_guid":"d70fba4c-2955-4fdc-9775-426729df8fd1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T05:38:12.821947Z","iopub.execute_input":"2024-10-20T05:38:12.822343Z","iopub.status.idle":"2024-10-20T05:38:15.038308Z","shell.execute_reply.started":"2024-10-20T05:38:12.822306Z","shell.execute_reply":"2024-10-20T05:38:15.037184Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab426bbc56734a09bc387a605066219f"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Move model to GPU (if available)\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel.to(device)","metadata":{"_uuid":"c1838ef3-9f6f-4fb1-9922-d84f7fe0b3e5","_cell_guid":"08672bc4-bfe1-474b-b821-3f75f4a03110","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T05:38:15.040022Z","iopub.execute_input":"2024-10-20T05:38:15.040352Z","iopub.status.idle":"2024-10-20T05:38:15.305235Z","shell.execute_reply.started":"2024-10-20T05:38:15.040317Z","shell.execute_reply":"2024-10-20T05:38:15.30412Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=7, bias=True)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"## You are free to use whatever type of trainers you want after this part for your purpose","metadata":{}},{"cell_type":"markdown","source":"<bR> --------------------------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# Deepspeed Part","metadata":{}},{"cell_type":"code","source":"!pip install deepspeed\nimport deepspeed","metadata":{"_uuid":"d3e9ecef-faca-40b9-a8cb-c62355926e37","_cell_guid":"e2f639e8-7db5-4bcf-b9d1-018d85b195c1","execution":{"iopub.status.busy":"2024-10-20T05:38:19.708177Z","iopub.execute_input":"2024-10-20T05:38:19.708552Z","iopub.status.idle":"2024-10-20T05:38:31.568129Z","shell.execute_reply.started":"2024-10-20T05:38:19.708517Z","shell.execute_reply":"2024-10-20T05:38:31.566672Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: deepspeed in /opt/conda/lib/python3.10/site-packages (0.15.2)\nRequirement already satisfied: hjson in /opt/conda/lib/python3.10/site-packages (from deepspeed) (3.1.0)\nRequirement already satisfied: msgpack in /opt/conda/lib/python3.10/site-packages (from deepspeed) (1.0.8)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from deepspeed) (1.11.1.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from deepspeed) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from deepspeed) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from deepspeed) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from deepspeed) (9.0.0)\nRequirement already satisfied: pydantic>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from deepspeed) (2.9.2)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from deepspeed) (2.4.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from deepspeed) (4.66.4)\nRequirement already satisfied: nvidia-ml-py in /opt/conda/lib/python3.10/site-packages (from deepspeed) (11.495.46)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->deepspeed) (3.1.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed) (2.23.4)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed) (4.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->deepspeed) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->deepspeed) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## You need mpi4y to run deepspeed","metadata":{}},{"cell_type":"code","source":"!conda install -y mpi4py","metadata":{"execution":{"iopub.status.busy":"2024-10-20T05:38:31.570696Z","iopub.execute_input":"2024-10-20T05:38:31.571172Z","iopub.status.idle":"2024-10-20T05:39:41.397124Z","shell.execute_reply.started":"2024-10-20T05:38:31.571116Z","shell.execute_reply":"2024-10-20T05:39:41.396111Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Channels:\n - rapidsai\n - nvidia\n - nodefaults\n - conda-forge\n - defaults\n - pytorch\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n# All requested packages already installed.\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# To run train the model using Deepseed while utilizing multiple gpu \n##### (kaggle does not have native multi-gpu processing(CLI) support.<br>\n\n\n#### **1. Create a .py file with all the preprocessing and working of the model inside a main function using %%write(as below)**\n(You can convert a notebook file to .py by going to the file section and selcting script in editor type)\n\n#### 2. add  if ＿name＿ == '＿main＿': main() at the end of the file \n\n#### 3. Run using accelerate launch\n","metadata":{}},{"cell_type":"code","source":"%%writefile train.py\n\ndef main():\n    \n    # Import necessary packages\n    import pandas as pd\n    import re\n    from sklearn.preprocessing import LabelEncoder\n    from sklearn.model_selection import train_test_split\n    from transformers import BertTokenizerFast, BertForSequenceClassification\n    import torch\n    from torch import nn\n    from torch.utils.data import DataLoader\n    from transformers import Adafactor\n    from tqdm import tqdm\n    import deepspeed\n    import json\n    from accelerate import Accelerator\n    from torch.optim import AdamW\n    from transformers import get_linear_schedule_with_warmup\n    from sklearn.metrics import f1_score, classification_report\n\n    # Load dataset\n    df = pd.read_csv(\"/kaggle/input/sentiment-analysis-for-mental-health/Combined Data.csv\")\n\n    # Convert 'statement' column to string\n    df[\"str_statement\"] = df[\"statement\"].astype(str)\n    # Ensure all values in 'str_statement' are strings\n    df[\"str_statement\"] = df[\"str_statement\"].astype(str)\n\n    # Convert to lowercase\n    df['str_statement'] = df['str_statement'].str.lower()\n    \n    def remove_patterns(text):\n        if isinstance(text, str):\n            # URL Removal\n            text = re.sub(r'http[s]?://\\S+','',text)\n            # Remove markdown style links\n            text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)\n            # Remove handles (that start with '@')\n            text = re.sub(r'@\\w+', '', text)\n            # Remove punctuation and other special characters\n            text = re.sub(r'[^\\w\\s]', '', text)\n            return text.strip()\n    \n    df['str_statement'] = df['str_statement'].apply(remove_patterns)\n\n    df.dropna(inplace=True)\n    \n    # Label encoding\n    label_encoder = LabelEncoder()\n    df['encoded_status'] = label_encoder.fit_transform(df['status'])\n    \n    # Initialize the tokenizer for BERT\n    tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n\n    # Split data into training and validation sets\n    train_texts, val_texts, train_labels, val_labels = train_test_split(\n        df['str_statement'], df['encoded_status'], test_size=0.25, random_state=42\n    )\n\n    # Tokenization\n    max_length = 512\n    train_encodings = tokenizer(train_texts.tolist(), padding='max_length', truncation=True, return_tensors='pt')\n    val_encodings = tokenizer(val_texts.tolist(), padding='max_length', truncation=True, return_tensors='pt')\n\n    # PyTorch Dataset Class\n    class MentalHealthDataset(torch.utils.data.Dataset):\n        def __init__(self, encodings, labels):\n            self.encodings = encodings\n            self.labels = torch.tensor(labels)\n\n        def __getitem__(self, idx):\n            item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n            item['labels'] = self.labels[idx].clone().detach()\n            return item\n\n        def __len__(self):\n            return len(self.labels)\n\n    # Create datasets\n    train_dataset = MentalHealthDataset(train_encodings, train_labels.tolist())\n    val_dataset = MentalHealthDataset(val_encodings, val_labels.tolist())\n\n    # Create DataLoader for both training and validation datasets\n    train_loader = DataLoader(train_dataset, batch_size=54, shuffle=True,pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=54)\n\n    # Define the BERT model\n    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=7)\n\n    # Move model to GPU (if available)\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n    model.to(device)\n\n    ds_config =\"\"\"\n    {\n    \"train_batch_size\": 54,\n    \"gradient_accumulation_steps\": 1,\n    \"fp16\": {\n        \"enabled\": true,\n        \"min_loss_scale\":1\n    },\n    \"zero_optimization\": {\n        \"stage\": 2,\n        \"allgather_partitions\": true,\n        \"reduce_scatter\": true,\n        \"overlap_comm\": true,\n        \"cpu_offload\": true\n    },\n    \"autotuning\": {\n        \"enabled\": true,\n        \"arg_mappings\": {\n            \"train_micro_batch_size_per_gpu\": \"--per_device_train_batch_size\",\n            \"gradient_accumulation_steps\": \"--gradient_accumulation_steps\"\n        }\n        },\n    \"gradient_clipping\": 1.0,\n    \"results_dir\": \"./autotuning_results\",\n    \"exps_dir\": \"./autotuning_exps\",\n    \"zero_allow_untested_optimizer\": true,\n    \"steps_per_print\": 2000,\n    \"wall_clock_breakdown\": false,\n    \"scheduler\": {\n    \"type\": \"WarmupLR\",\n    \"params\": {\n      \"warmup_min_lr\": 0,\n      \"warmup_max_lr\": 0.001,\n      \"warmup_num_steps\": 1000\n      }\n      }\n    \"optimizer\": {\n           \"type\": \"AdamW\",\n           \"params\": {\n               \"lr\": 1e-4,\n               \"betas\": [0.9, 0.999],\n               \"eps\": 1e-8,\n               \"weight_decay\": 0.01\n        }   \n      }\n    }\n\n    \"\"\"\n    # DeepSpeed Initialization\n    with open(\"ds_config.json\", \"w\") as f:\n        f.write(ds_config)\n   \n    #optimizer = AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\n    model_engine,optimizer, _, _ = deepspeed.initialize(\n    model=model,\n    config=\"ds_config.json\" )\n    \n    model = model.to(device)\n    \n    accelerator = Accelerator()\n    \n    # Training loop\n    from tqdm import tqdm\n    from collections import OrderedDict\n    \n    criterion = nn.CrossEntropyLoss()\n    epochs = 1\n    num_batches = len(train_loader)\n    total_steps = (num_batches) * (epochs)\n  \n    # Initialize a single progress bar\n    progress_bar = tqdm(total=epochs * num_batches, desc=\"Training Progress\")\n\n\n    def train_one_epoch(model, train_loader,criterion,optimizer,accelarator, device):\n        model.train()  # Set model to training mode\n        total_loss = 0\n\n        # Use tqdm for progress bar\n        with tqdm(train_loader, leave=True, disable=not accelerator.is_local_main_process) as pbar:\n            for idx, batch in enumerate(pbar):\n                batch = {k: v.to(device) for k, v in batch.items()}  # Move batch to device\n\n                outputs = model(**batch)\n                loss = outputs.loss  # Assuming outputs has a loss attribute\n            \n                # Backward pass with accelerator\n                model_engine.backward(loss)  # Automatic handling of backward pass\n            \n                # Update the loss and progress bar\n                total_loss += loss.item()\n                pbar.set_postfix(OrderedDict(loss=f'{loss.item():.6f}'))\n\n                # Step the optimizer\n                optimizer.step()\n                optimizer.zero_grad()  # Clear gradients\n            \n                # Update the progress bar\n                pbar.update(1)  \n\n        # Wait for all processes to finish\n        accelerator.wait_for_everyone()\n        # Log average loss\n        accelerator.print(f'train_loss: {total_loss / len(train_loader):.6f}')\n\n    # Training loop\n    for epoch in range(epochs):\n        train_one_epoch(model, train_loader,criterion, optimizer, accelerator, device)\n        print(f\"Epoch {epoch + 1} completed.\")\n\n\n\n    # Move model to GPU (if available)\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n    model.to(device)\n\n    model.eval()\n    if torch.cuda.device_count() > 1:\n        model = torch.nn.DataParallel(model)\n\n\n    val_loader = DataLoader(val_dataset, batch_size=1024)\n\n    # Store predictions and true labels\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for batch in tqdm(val_loader, desc=\"Making Predictions\", unit=\"batch\"):\n            # Move the batch to the GPU (if available)\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            # Forward pass\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n\n            # Get the predicted labels\n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            labels = labels.cpu().numpy()\n\n            # Store predictions and true labels\n            all_preds.extend(preds)\n            all_labels.extend(labels)\n\n    # Calculate the F1-score\n    f1 = f1_score(all_labels, all_preds, average='weighted')\n    print(f'Validation F1-score: {f1:.4f}')\n\n\n    # Save the trained model\n    model.save_pretrained(\"./trained_model\")\n    \nif __name__ == '__main__':\n    main()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T05:45:20.487111Z","iopub.execute_input":"2024-10-20T05:45:20.487493Z","iopub.status.idle":"2024-10-20T05:45:20.499053Z","shell.execute_reply.started":"2024-10-20T05:45:20.487456Z","shell.execute_reply":"2024-10-20T05:45:20.497873Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Overwriting train.py\n","output_type":"stream"}]},{"cell_type":"code","source":"import accelerate","metadata":{"execution":{"iopub.status.busy":"2024-10-20T05:39:41.413271Z","iopub.execute_input":"2024-10-20T05:39:41.413564Z","iopub.status.idle":"2024-10-20T05:39:41.427982Z","shell.execute_reply.started":"2024-10-20T05:39:41.413526Z","shell.execute_reply":"2024-10-20T05:39:41.426985Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"## Start training using accelerate launch","metadata":{}},{"cell_type":"code","source":"os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # To avoid warnings","metadata":{"execution":{"iopub.status.busy":"2024-10-20T05:45:29.462227Z","iopub.execute_input":"2024-10-20T05:45:29.463004Z","iopub.status.idle":"2024-10-20T05:45:29.498797Z","shell.execute_reply.started":"2024-10-20T05:45:29.462965Z","shell.execute_reply":"2024-10-20T05:45:29.497523Z"},"trusted":true},"execution_count":56,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTOKENIZERS_PARALLELISM\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# To avoid warnings\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"],"ename":"NameError","evalue":"name 'os' is not defined","output_type":"error"}]},{"cell_type":"code","source":"!accelerate launch train.py --precision fp16 # using fp16 mixed-precision","metadata":{"execution":{"iopub.status.busy":"2024-10-20T05:45:31.017816Z","iopub.execute_input":"2024-10-20T05:45:31.01875Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"[2024-10-20 05:45:42,058] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2024-10-20 05:45:42,060] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Thank You ( Do upvote if you like this notebook)","metadata":{}}]}